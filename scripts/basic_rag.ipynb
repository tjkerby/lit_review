{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review')\n",
    "import utils\n",
    "\n",
    "sys.path.append('C:/Users/tjker/Desktop/Research/Projects/lit_review/configs')\n",
    "from create_chunks_config import config\n",
    "\n",
    "kg = utils.load_kg(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jVector\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint\n",
    "# from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import textwrap\n",
    "\n",
    "load_dotenv('C:/Users/tjker/Desktop/Research/Projects/lit_review/.env', override=True)\n",
    "\n",
    "llm = HuggingFaceEndpoint(model=config['model']['model_id'])\n",
    "\n",
    "chunk_vector = Neo4jVector.from_existing_index(\n",
    "    HuggingFaceEmbeddings(model_name=config['embedding']['model_id']),\n",
    "    graph=kg,\n",
    "    index_name='paper_chunks',\n",
    "    embedding_node_property='textEmbedding',\n",
    "    text_node_property='text',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Powerful Querying capability\n",
    "A query like the following:\n",
    "```\n",
    "MATCH (p:Paper)-[:HAS_CHUNK]->(c:Chunk)\n",
    "WHERE p.publication_date >= $min_date AND p.author = $desired_author\n",
    "WITH c, p, vector.similarity.cosine(c.embedding, $embedding) AS score\n",
    "ORDER BY score DESC LIMIT $k\n",
    "RETURN c, score, {title: p.title, url: p.url} AS metadata\n",
    "```\n",
    "\n",
    "Allows me to first filter the vector database that I look at and then perform RAG. This is far more targeted than looking at all chunks in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA with sources retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_response(response):\n",
    "    print(\"Question:\")\n",
    "    print(response.get(\"question\", \"\"))\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(response.get(\"answer\", \"\"))\n",
    "    print(\"\\nSources:\")\n",
    "    # If your sources key contains a string or list, print it nicely\n",
    "    sources = response.get(\"sources\", [])\n",
    "    if isinstance(sources, list):\n",
    "        for i, src in enumerate(sources, start=1):\n",
    "            print(f\"  [{i}] {src}\")\n",
    "    else:\n",
    "        print(sources)\n",
    "    print(\"\\nDetailed Source Documents:\")\n",
    "    docs = response.get(\"source_documents\", [])\n",
    "    for i, doc in enumerate(docs, start=1):\n",
    "        # Customize as needed; here we assume each doc is a Document object with metadata\n",
    "        title = doc.metadata.get(\"source\", \"Unknown Source\")\n",
    "        text_snippet = doc.page_content.replace(\"\\n\", \" \") + \"...\"\n",
    "        print(f\"Source {i}: {title}\")\n",
    "        print(f\"Snippet: {text_snippet}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
    "\n",
    "custom_query = \"\"\"\n",
    "MATCH (c:Chunk)\n",
    "WITH DISTINCT c, vector.similarity.cosine(c.textEmbedding, $embedding) AS score\n",
    "ORDER BY score DESC LIMIT $k\n",
    "RETURN c.text AS text, score, {source: c.source, chunkId: c.chunkId} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "filtered_chunk_vector = Neo4jVector.from_existing_index(\n",
    "    HuggingFaceEmbeddings(model_name=config['embedding']['model_id']),\n",
    "    graph=kg,\n",
    "    index_name='paper_chunks',\n",
    "    embedding_node_property='textEmbedding',\n",
    "    text_node_property='text',\n",
    "    retrieval_query=custom_query,\n",
    ")\n",
    "\n",
    "# retriever = filtered_chunk_vector.as_retriever()\n",
    "retriever_k = filtered_chunk_vector.as_retriever(search_kwargs={\n",
    "        \"k\": 3\n",
    "    })\n",
    "\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever_k,\n",
    "    return_source_documents=True,  # so you get citations back\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are some ways that you can leverage the structure of a latent space to influence generation?\"\n",
    "response = qa_chain.invoke({\"question\": question})\n",
    "# Then call your display function:\n",
    "display_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textwrap.fill(response['answer'], 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are some ways that you can leverage the structure of a latent space to influence generation?\"\n",
    "response = chunk_retriever.invoke({\"query\": question})\n",
    "\n",
    "print(textwrap.fill(response['result'], 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"How can we uncover the underlying structure of the latent space in GANs and Diffusion Models?\"\n",
    "# result = chunk_vector.similarity_search(question, k=3)\n",
    "# for doc in result:\n",
    "#     print(doc.metadata[\"chunkId\"], \"-\", doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever_0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are some ways that the structure of a latent space can be leveraged to influence the generation process?\"\n",
    "response = chain.invoke({\"question\": question},\n",
    "        return_only_outputs=True,)\n",
    "\n",
    "# print(textwrap.fill(response['result'], 60))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def prettychain(question: str) -> str:\n",
    "    \"\"\"Pretty print the chain's response to a question\"\"\"\n",
    "    response = chain.invoke({\"question\": question},\n",
    "        return_only_outputs=True,)\n",
    "    print(textwrap.fill(response['answer'], 60))\n",
    "    \n",
    "prettychain('who wrote Self-Guided Diffusion Models?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": 'who wrote Self-Guided Diffusion Models?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": 'who wrote DiGress: Discrete Denoising diffusion for graph generation?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old graph_rag.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():     \n",
    "        outputs = model(**inputs) \n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze(0).tolist()\n",
    "\n",
    "question = \"Transformer architecture\"\n",
    "# question_embedding = model.encode(question)\n",
    "question_embedding = compute_embedding(question)\n",
    "\n",
    "kg.query(\"\"\"\n",
    "    CALL db.index.vector.queryNodes(\n",
    "        'abstract_embeddings', \n",
    "        $top_k, \n",
    "        $question_embedding\n",
    "        ) YIELD node AS paper, score\n",
    "    RETURN paper.title, paper.abstract, score\n",
    "    \"\"\", \n",
    "    params={\"top_k\":5,\n",
    "            \"question_embedding\": question_embedding\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Latent Space Editing in Transformer-Based Flow Matching'\n",
    "kg.query(\"\"\"\n",
    "    CALL db.index.fulltext.queryNodes('paperTitleIndex', $title)     \n",
    "    YIELD node, score\n",
    "    RETURN node.paperId, score\n",
    "    LIMIT 1\n",
    "    \"\"\", params={'title': title}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
