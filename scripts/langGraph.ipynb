{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    \n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "\n",
    "# class Agent:\n",
    "#     def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "#         self.system = system\n",
    "#         graph = StateGraph(AgentState)\n",
    "#         graph.add_node(\"llm\", self.call_model)\n",
    "#         graph.add_edge(START, \"llm\")\n",
    "#         graph.add_node(\"action\", self.take_action)\n",
    "#         graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "#         graph.add_edge(\"action\", \"llm\")\n",
    "#         graph.set_entry_point(\"llm\")\n",
    "#         graph.add_node(\"stream_buffer\", self.handle_partial_outputs) # FIXME\n",
    "#         self.graph = graph.compile(checkpointer=checkpointer)\n",
    "#         self.tools = {t.name: t for t in tools}\n",
    "#         self.model = model.bind_tools(tools)\n",
    "\n",
    "#     # def call_model(self, state: AgentState):\n",
    "#     #     messages = state['messages']\n",
    "#     #     if self.system:\n",
    "#     #         messages = [SystemMessage(content=self.system)] + messages\n",
    "#     #     message = self.model.invoke(messages)\n",
    "#     #     return {'messages': [message]}\n",
    "#     def call_model(self, state: AgentState):\n",
    "#         messages = state['messages']\n",
    "#         if self.system:\n",
    "#             messages = [SystemMessage(content=self.system)] + messages\n",
    "#         for chunk in self.model.stream(messages):\n",
    "#             yield {\"messages\": [chunk]}\n",
    "#             if chunk.tool_calls:\n",
    "#                 break  # Pause for tool execution\n",
    "            \n",
    "#     def handle_partial_outputs(self, state: AgentState): # FIXME\n",
    "#         buffer = state.get('buffer', '')\n",
    "#         for event in state['messages']:\n",
    "#             if isinstance(event, str):\n",
    "#                 buffer += event\n",
    "#                 if len(buffer) > 50:  # Flush buffer\n",
    "#                     print(buffer, end='', flush=True)\n",
    "#                     buffer = ''\n",
    "#         return {'buffer': buffer}\n",
    "\n",
    "#     def exists_action(self, state: AgentState):\n",
    "#         result = state['messages'][-1]\n",
    "#         return len(result.tool_calls) > 0\n",
    "\n",
    "#     # def take_action(self, state: AgentState):\n",
    "#     #     tool_calls = state['messages'][-1].tool_calls\n",
    "#     #     results = []\n",
    "#     #     for t in tool_calls:\n",
    "#     #         print(f\"Calling: {t}\")\n",
    "#     #         result = self.tools[t['name']].invoke(t['args'])\n",
    "#     #         results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "#     #     print(\"Back to the model!\")\n",
    "#     #     return {'messages': results}\n",
    "    \n",
    "#     async def take_action(self, state: AgentState):\n",
    "#         tool_calls = state['messages'][-1].tool_calls\n",
    "#         tasks = [asyncio.create_task(self._execute_tool(t)) \n",
    "#                 for t in tool_calls]\n",
    "        \n",
    "#         while tasks:\n",
    "#             done, _ = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "#             for task in done:\n",
    "#                 yield {'messages': [task.result()]}\n",
    "#             tasks = [t for t in tasks if not t.done()]\n",
    "\n",
    "# import asyncio\n",
    "# from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage\n",
    "# from langgraph.graph import StateGraph, END, START\n",
    "# from typing import TypedDict, Annotated\n",
    "# import operator\n",
    "\n",
    "# class AgentState(TypedDict):\n",
    "#     messages: Annotated[list[AnyMessage], operator.add]\n",
    "#     buffer: str\n",
    "\n",
    "# class Agent:\n",
    "#     def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "#         self.system = system\n",
    "#         graph = StateGraph(AgentState)\n",
    "#         graph.add_node(\"llm\", self.call_model)\n",
    "#         graph.add_edge(START, \"llm\")\n",
    "#         graph.add_node(\"action\", self.take_action)\n",
    "#         graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "#         graph.add_edge(\"action\", \"llm\")\n",
    "#         graph.set_entry_point(\"llm\")\n",
    "#         graph.add_node(\"stream_buffer\", self.handle_partial_outputs)\n",
    "#         graph.add_edge(\"llm\", \"stream_buffer\")\n",
    "#         graph.add_edge(\"stream_buffer\", END)\n",
    "#         self.graph = graph.compile(checkpointer=checkpointer)\n",
    "#         self.tools = {t.name: t for t in tools}\n",
    "#         self.model = model.bind_tools(tools)\n",
    "\n",
    "#     async def call_model(self, state: AgentState):\n",
    "#         messages = state['messages']\n",
    "#         if self.system:\n",
    "#             messages = [SystemMessage(content=self.system)] + messages\n",
    "#         async for chunk in self.model.astream(messages):\n",
    "#             yield {\"messages\": [chunk]}\n",
    "#             if chunk.tool_calls:\n",
    "#                 break  # Pause for tool execution\n",
    "\n",
    "#     def handle_partial_outputs(self, state: AgentState):\n",
    "#         buffer = state.get('buffer', '')\n",
    "#         for event in state['messages']:\n",
    "#             if isinstance(event, AIMessage):\n",
    "#                 content = event.content or \"\"\n",
    "#                 buffer += content\n",
    "#                 if len(buffer) > 50:  # Flush buffer\n",
    "#                     print(buffer, end='', flush=True)\n",
    "#                     buffer = ''\n",
    "#         return {'buffer': buffer}\n",
    "\n",
    "#     def exists_action(self, state: AgentState):\n",
    "#         result = state['messages'][-1]\n",
    "#         return hasattr(result, 'tool_calls') and len(result.tool_calls) > 0\n",
    "\n",
    "#     async def take_action(self, state: AgentState):\n",
    "#         tool_calls = state['messages'][-1].tool_calls\n",
    "#         tasks = [asyncio.create_task(self._execute_tool(t)) \n",
    "#                 for t in tool_calls]\n",
    "        \n",
    "#         results = []\n",
    "#         while tasks:\n",
    "#             done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "#             for task in done:\n",
    "#                 results.append(await task)\n",
    "        \n",
    "#         return {'messages': results}\n",
    "\n",
    "#     async def _execute_tool(self, tool_call):\n",
    "#         print(f\"Calling: {tool_call}\")\n",
    "#         result = await self.tools[tool_call.name].ainvoke(tool_call.arguments)\n",
    "#         return ToolMessage(tool_call_id=tool_call.id, name=tool_call.name, content=str(result))\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    buffer: str\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_model)\n",
    "        graph.add_edge(START, \"llm\")\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        graph.add_node(\"stream_buffer\", self.handle_partial_outputs)\n",
    "        graph.add_edge(\"llm\", \"stream_buffer\")\n",
    "        graph.add_edge(\"stream_buffer\", END)\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    async def call_model(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        async for chunk in self.model.astream(messages):\n",
    "            print(f\"Received chunk: {chunk}\")\n",
    "            yield {\"messages\": [chunk], \"buffer\": chunk.content if chunk.content else \"\"}\n",
    "            if chunk.tool_calls:\n",
    "                break  # Pause for tool execution\n",
    "\n",
    "    def handle_partial_outputs(self, state: AgentState):\n",
    "        buffer = state.get('buffer', '')\n",
    "        return {'buffer': buffer}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return hasattr(result, 'tool_calls') and len(result.tool_calls) > 0\n",
    "\n",
    "    async def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        tasks = [asyncio.create_task(self._execute_tool(t)) \n",
    "                for t in tool_calls]\n",
    "        \n",
    "        results = []\n",
    "        while tasks:\n",
    "            done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n",
    "            for task in done:\n",
    "                results.append(await task)\n",
    "        \n",
    "        return {'messages': results}\n",
    "\n",
    "    async def _execute_tool(self, tool_call):\n",
    "        print(f\"Calling: {tool_call}\")\n",
    "        tool_name = tool_call.name if hasattr(tool_call, 'name') else tool_call.get('name')\n",
    "        \n",
    "        # Handle different possible structures of tool_call\n",
    "        if hasattr(tool_call, 'arguments'):\n",
    "            tool_args = tool_call.arguments\n",
    "        elif 'arguments' in tool_call:\n",
    "            tool_args = tool_call['arguments']\n",
    "        elif 'args' in tool_call:\n",
    "            tool_args = tool_call['args']\n",
    "        else:\n",
    "            tool_args = {}\n",
    "\n",
    "        # If tool_args is a string, try to parse it as JSON\n",
    "        if isinstance(tool_args, str):\n",
    "            try:\n",
    "                tool_args = json.loads(tool_args)\n",
    "            except json.JSONDecodeError:\n",
    "                # If it's not valid JSON, use it as is\n",
    "                tool_args = {\"question\": tool_args}\n",
    "\n",
    "        # Ensure tool_args is a dictionary\n",
    "        if not isinstance(tool_args, dict):\n",
    "            tool_args = {\"question\": str(tool_args)}\n",
    "\n",
    "        # Ensure 'k' is present in tool_args\n",
    "        if 'k' not in tool_args:\n",
    "            tool_args['k'] = 10  # default value\n",
    "\n",
    "        result = await self.tools[tool_name].ainvoke(input=tool_args)\n",
    "        return ToolMessage(\n",
    "            tool_call_id=tool_call.id if hasattr(tool_call, 'id') else tool_call.get('id', ''),\n",
    "            name=tool_name,\n",
    "            content=str(result)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/TomKerby/Research/lit_review/configs')\n",
    "from new_llm_config import config\n",
    "\n",
    "sys.path.append('/home/TomKerby/Research/lit_review/lit_review')\n",
    "import utils\n",
    "from agent_tools import SearchNeo4jVectorTool\n",
    "import rag_utils as rag\n",
    "\n",
    "from langchain_neo4j import Neo4jVector\n",
    "\n",
    "kg = utils.load_kg(config)\n",
    "# llm_adapter = rag.get_llm(config)\n",
    "emb_adapter = rag.get_embeddings(config)\n",
    "\n",
    "custom_query = \"\"\"\n",
    "MATCH (c:Chunk)\n",
    "WITH DISTINCT c, vector.similarity.cosine(c.textEmbedding, $embedding) AS score\n",
    "ORDER BY score DESC LIMIT $k\n",
    "RETURN c.text AS text, score, {source: c.source, chunkId: c.chunkId} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "chunk_vector = Neo4jVector.from_existing_index(\n",
    "    emb_adapter.embeddings,\n",
    "    graph=kg, \n",
    "    index_name=config[\"rag\"][\"index_name\"],\n",
    "    embedding_node_property=config[\"rag\"][\"embedding_node_property\"],\n",
    "    text_node_property=config[\"rag\"][\"text_node_property\"],\n",
    "    retrieval_query=custom_query,\n",
    ")\n",
    "\n",
    "tool = SearchNeo4jVectorTool(vector_db=chunk_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "llm_config = config['llm']\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=llm_config[\"model_id\"],\n",
    "    num_ctx=llm_config.get(\"num_ctx\", 32768),\n",
    "    num_predict=llm_config.get(\"num_predict\", 4096),\n",
    "    temperature=llm_config.get(\"temperature\", 0.5)\n",
    ")\n",
    "\n",
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAFlCAIAAABX0NXvAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdAU1ffB/CTPQkBwh4CojhQQcWJq4pVi9sqbmqto1otWutobbFa9XFUrYgLNy60KoqtC0XFqnWhQiuCG5A9s8h8/7jPS3lUlECSc2/y+/wVrknOT8Y355577jk0vV6PAACgbui4CwAAUAlEBgDAABAZAAADQGQAAAwAkQEAMABEBgDAAEzcBQDTKnxVJavQyCq06ipdlUKHu5w6YfPoLBaNL2IKREznRhzc5YD/QYN5GRbpeZrsSZrs2UOpV3OBSqEViJh2zmy1ihqRweEySvJVsgoNg0l7/rfMJ0DQuJWNX6AAd10AQWRYoKcPZNdOFbn58lx9ub4BQq6A2ueeapX+WZr0xT/yl4/kXQY6NO8gwl2RtYPIsBzqKv25uDwaDXUZKBE7snCXY2QKqfbayaLSAnXfcc62Ekv731EIRIaFeP1MeXJLzvBZHhJ3Sz75Ly9SJ2zJDRkk8W0N5yl4QGRYgtJ8VdKhghGzPXAXYia/73zdprvY3Y+HuxBrBJFBec/TZXculA63mrwgnI593ag5P6CrLe5CrA61x8ZAZakm+WihteUFQuiTya6Pble+fqbEXYjVgcigtqRDBeMWNMJdBR4jZnv8dbZEpaTGlWOLAZFBYX+dKXHz4TI5NNyFYOMXKExJKMJdhXWByKAqrVp/J6m0Qz973IXg1LKTKCdLUV6kxl2IFYHIoKq7F8t6fuponra0Wm1qamq9Xy6VSh89emTUiv7VfZjjg6vlJnpz8DaIDKpKv1Hu0YRvnraWLl26fPnyer88PDw8ISHBqBX9q1Ez/v0rZSZ6c/A2iAxKKspRcfl0Gzsz3VVYVVVVvxcSl/BVKpWxK6qBhrxbCp6ly0zYBKgB5mVQUmpymV6PgnqJjf7OKSkpGzduzM7OdnNzGzFixKhRo6KiohITE6ufcPLkSTc3t5MnT8bHx2dlZfH5/M6dO3/zzTd2dnYIoQsXLixYsGDNmjX79u1LT0+fOHHi6dOn8/LyiNe6uLjUfCtjybwrzX+lDBksMfo7g7fBze+UVJhT5elv/LMSuVw+f/58X1/f77//Pisrq7CwECE0adKk/Pz8nJycn376CSEkkUgQQg8fPvT29h4wYEBJScmhQ4dkMtn69eur3+c///nPjBkzpk+f7uXl1aNHj5kzZ7Zr127s2LFsNtvoNSOEBGJm/jWYoGEmEBmUJCvXCEXG/9mVlJRUVVV99NFH/fv3rz7o5eUlFouLi4sDAwOrDy5atIhG++/FXSaTuXPnzqqqKg7nv7e3jBo1KiwsjHjs5OTEZDIlEknNlxsX34Yhr9Ca6M3BGyAyKElWoeWLGEZ/W3d399atW+/YsYPH4w0bNuw9nQK1Wn3o0KHff/89Ly+Py+XqdLrS0lIXFxfiXzt06GD02t5DIGLIKzXmbNGawfAnJTFZNAbD+DO4aDTar7/+GhYWtn79+mHDht29e/edT9Pr9V9//fXOnTsHDRoUHR09YMAAhJBO9+8sTD7fTJdyCDQ6jc01foCCd4LIoCQWhy4tN8nnqlAoXLBgwW+//SYUCufMmSOXy4njNYfJ7969+9dffy1YsGDMmDEBAQF+fn4ffFuTjrLLKzQM6C6bC0QGJQlEpjp7J66nuru7h4eHS6XS3NxchBCPxysuLq7uR5SVlSGEmjVrVvPLmr2MN/B4vKIiE07rlldq+TaQGWYC32hKkrhxqkxwO5ZarR4+fHhoaGjjxo2PHDkiFAo9PDwQQm3btj158uTy5csDAwNFIlGrVq3YbHZ0dPTQoUMzMzN37dqFEMrKyiKe/LagoKAzZ87s3r1bJBK1bt26Lr0SgyhlWpdGXOO+J6gNIyoqCncNwGA0REtNLm3R0cgLYcpkspcvX166dOnixYuOjo5RUVFECvj5+ZWXl585c+bu3btisbhXr16+vr6nTp06deqURqNZtmxZQUFBampqWFjY06dPL1y4MHLkSLH43zkjrVu3zsjI+P333x89etSyZUsfHx/jlv3XuVK3xjyJmyUvR0YeMJWLqrYtfDrxB28OD04t0db5Tyb95Muy4jt6zQlOTKiqZWdR9mNF4za1LoGZlJS0dOnSt49zOJzaJoDv2rXL6F2AN0il0uopG2+ws7MrLS19+/i6deuCgoJqe8O8Z0q/IBvIC7OBXgZVVZRojkdnT/zBu7YnKBSKd/4FqlSq2iZcENOujFrmm3Q6XfX88Teo1WoW6x1Lhzs4OFRPEnvbb79mdwmTuPrCWIaZQC+DqkT2zEbNBWnXymtb/5LH4/F4pFtQl06nu7m5GevdnqfLODw65IU5wZkwhXUJc3j60Krv4My4Le0y0EyLhgACRAaFsXn0tr3tTsTk4C4Ejwv78xu14Nu7wDZIZgWRQW0eTXjeLQUX9ufjLsTcrp0s5goZzYJtcBdidWD40xI8fSh7+lDaZ4wz7kLM5M/EYqGY2ToENjHBAHoZlsC3lcDVh3dkfbZWbfkfAKd3vGaxaZAXuEAvw3LkPVcmHy30aSno2N8ylx2/d6ns3qXSnp86+baCDVmxgciwKHo9un2+5Na5ko79HDya8p29LGEOdfFr1fN02b3ksmbBNl3CJHS4zR0riAwLpNPqU6+UZaVKpaWa5h1t9To9X8QQ2bN0Omr8rBkMWmWpRlah0etQ5r1KNpfeuLWwVYgtTwhpgR9EhiWTV2hzshQVpWp5hVavR7IKIy+x8fr166qqKm/vWmeg1o9QzNTr9Hwbpo0d09WXJ7KHCYckAj8MS8YXMZq0FZru/Q8cuFj6+nX/iE6mawKQDVwxAQAYACIDAGAAiAxQf3w+XyQy8jI/gOQgMkD9yeXyiooK3FUAs4LIAPXHZDJNtAEaIC2IDFB/Go3GtFs0A/KByAD1x2azuVxY3sa6QGSA+lOpVEol7J9sXSAyQP3x+fyamw8AawCRAepPLpcTW6UB6wGRAQAwAEQGqD8Wi/We7QKARYLIAPWnVqtr20UJWCqIDFB/0MuwQhAZoP6gl2GFIDIAAAaAyAD1x+PxhEITLuEDSAgiA9SfQqGQSqW4qwBmBZEBADAARAaoPz6fb2sLWxBZF4gMUH9yuby8vBx3FcCsIDIAAAaAyAD1BycmVggiA9QfnJhYIYgMAIABIDJA/cGmBFYIIgPUH2xKYIUgMgAABoDIAPUH+5hYIYgMUH+wj4kVgsgA9Qd3slohiAxQf3AnqxWCyAAAGAAiA9Qfm82GtT+tDUQGqD+VSgVrf1obiAxQfzweD2Z/WhuIDFB/CoUCZn9aG4gMUH9w87sVgsgA9Qc3v1shiAxQfxwOh8/n464CmBVNr9fjrgFQzODBg/V6vV6vl8vlWq1WJBIRv0WnTp3CXRowOSbuAgD1NGnSJDk5ufpLYgJo+/btsRYFzAROTIDBJk2aZG9vX/OIra3t6NGj8VUEzAciAxisRYsWAQEBNU9pfX19e/TogbUoYCYQGaA+Pvvss+qOhq2t7YQJE3BXBMwEIgPUR6tWrQIDA4nHvr6+3bp1w10RMBOIDFBPEydOtLOzgy6GtYErJtZLXqktylGpqrT1ezkXeXdoOaiystJVFJR1v56rZjBZdIkbWyiG30PKgHkZ1kgp0108nP/6mdKrmUCp0GGsRGDDfPGPVOLOCRkksXNmYawE1BFEhtVRSLXHonNChrjYu5JlpV9pmebC/tzBU91EDtDdIDsYy7A6cctffBzhQZ68QAgJxcwhM7z2r3yhUcMHGNlBL8O63LtYVlWFWnYR4y7kHZ4+lFYWV4UMdsBdCHgf6GVYl7wXStKONYrsWTlZctxVgA+AyLAuGpXOxo5EpyQ1iexZepxDsaBOIDKsi1yq1elIeiqq1yNpmRp3FeADIDIAAAaAyAAAGAAiAwBgAIgMAIABIDIAAAaAyAAAGAAiAwBgAIgMAIABIDIAAAaAyAAAGAAiAwBgAIgM8D7l5WW9erdPOHmU+DL58oVevdu/fPkcd10AG4gMAIABIDIAAAYg6WorgBK+/2Gul6e3skp57lyiXq9vG9Rh+LDRcft3pKXft7dz+CxiWmjoANw1AiODXgZokIOH9iCEflm7ddTICSnXkufNn9G1a891v2zz8/NfuSoKRj0sD/QyQIM0auQza+Y8hFDTJs1+/+NEM/+WQ4eMRAjN+HLu1ZRLqffveHl5464RGBP0MkCDcNic6sdsNofJ+u9eJE5OzsQFF3ylAZOAyAAmQaPREEKwfr3lgcgAABgAIgO8D5PJQghVVlYQX7JZbIRQRUU57roANhAZ4H0EAoG7m0f8kbhTiccQQj6+fnQ6fd2GFfdSb+MuDeABkQE+4Lvvfvbw8Dp7LhEh5OriNn/ej1VVVTdupOCuC+ABGyxal8NrX3Xo7yRx59ThueZWJdediH4++Wdf3IWA94FeBgDAABAZAAADQGQAAAwAkWFFfv/9d5iOCRoIIsPyPXjwACH05MmT69ev8/kC3OUAaoPIsFgajQYhNGHChG3btiGEGjduvHTpUtb/3wNCTlqN9uXLl7irAO8DkWGBHjx4MHPmzKysLITQypUro6OjcVdUVzQ6bfbs2c+ePcNdCKgVRIblSEtLu3HjBkLo77//HjduXLNmzRBCbm5uuOsyAJ1OP378uL29PUJo+vTpxH8HkApEBuVJpVKE0Pnz51evXi0WixFC4eHhnTp1wl1X/dna2iKEZsyYkZSUhBB6/fo17orAvyAyKEyhUMyaNWv58uUIoU6dOu3Zs4foWViGgICA7777DiFUUVHRs2fPe/fu4a4IIIgMSnr8+PHq1asRQnK5fNSoUURk2NjY4K7LVPz9/RMTE4nR3FOnThUWFuKuyKpBZFBGSUlJQUEBQigmJsbHxwch5ODg0LVrV9x1mYNQKAwODkYI2dnZjR8/vri4WKfT4S7KSkFkUMPp06cjIyOJT9r169ePGDECd0V4hISEnDlzhsfjqVSqL7/8Mj09HXdFVgcig7zUavXq1avnz59PnNjv2bOn4Zc/xI5s0t65rNPrHT24dXkmn8/ncrkTJ078448/EEIwlcOcIDJIRyqVHjt2DCFUXFzs6em5dOlShFCjRo0a+LZlZWW3bt3i8OnFuUojVWpkxTlKOsOA53fs2PGbb75BCOXm5vbv3z8vL8+ExYH/B+tlkIhardZqtR9//PGoUaO+/PLLhr9hRkZGZmbmP//8k5mZmZ+fr1QqPR3ahofN6fiJozHqNbL7l0ocXJnNO4rq8dqCggKlUunl5bVjx46xY8dyuXXqrYB6gH1MSCEhIWHjxo0JCQkcDufy5csNf8Pp06fn5+crFIrS0lK1Wk2s981ms0MnBXK5tFtni4I/lhijcKNJu1Yqr1SHDLGv38udnJyIBwwGIzw8/MSJExqNhsmEX2/jg14GTidOnBAIBKGhoRcuXGjfvj0xEcsohg0b9vYZvru7+/Hjx+l0+rVTxfIKnaMn19GdS8N9blqUW1VWqJKWqgZ85mLEt83Ozo6Ojo6MjHR2djbi2wKIDAyeP3/u7e198ODBrKys6dOnSyQm+cAfMWLE8+f/7m9Io9GmTp06efJk4stnD2VZ96WqKl1xrsoozalVKp1ex+EYdkbg6MGhM1Cj5oJmwcafV3L+/PmcnJyIiIinT5/6+sL6gMYBkWFW2dnZX331Vf/+/adMmWKG5kJCQpTK/w52uri47Nu3z87OzkRt3bx5c8+ePTExMSZ6/4aIjY1NSUmJiYnh8/m4a6E83L1S63Dnzp2ff/6ZuCF9w4YN5smL8ePHR0ZGEgOBer2+V69epssLhJCPjw9p70CdPHny3LlziZtxLly4gLscaoPIMKGCgoIXL14QYxY9e/ZECHl7e3t5eZm63YyMjODg4IULFw4fPjwlJUWv17u6upp69peTk5NcLif+LEmoVatWxBBpcnLytGnTcJdDZXpgGomJif369Xvx4oWZ2z1+/Pjo0aO1Wm3Ng4sWLTJD0xMnTnz48KEZGmqgnJwcvV5/8uTJo0eP4q6FeqCXYUwajWbTpk0rVqwg5mv+8ccfZuhT1LR58+aHDx8eOHCATv+fnyxxWmRqPj4+T58+NUNDDURMog0NDc3IyLh9G7Z9MwxEhnGkpKQQl0J4PN7XX39tlPmahoqIiPDw8Fi8eLGZ260WEBBQUlKCq3VDcbncRYsWtWnTBiE0cODA5ORk3BVRA0RGgxD3iQ0bNuzMmTMIIT8/v0mTJvF4PDOX8ezZs06dOs2dO3fgwIFmbromZ2fn1NRUjAXUA7EY6u7du4lRpydPnuCuiOwgMuopPT09MjIyOzsbIbRjx45ly5bhquT06dNbt269evVqq1atcNVAoMqJydscHBwmTpxI3NcTFhaWk5ODuyLygsgwjEKhyMzMRAhdvXp16NCh3t7exCIOuOr55Zdfbt68uXLlSjIsHe7u7q7T6dRqNe5C6q9Dhw7bt28vKioiZprgLoeMIDIMkJycHBoaqlKpEELTpk3r3r073nqmTJni7Oz8008/4S2jJhsbG9LOzqgjV1dXYoDjypUrn3/+Oe5ySAfu2/mwxMTEoqKiiIgIV1dXYpgTu+zs7JUrV06dOrVdu3a4a/kf3t7ez58/b9q0Ke5CjGDevHmPHj1CCL148UKhUFjSuqoNAb2MWpWWlhK909u3b/ft25dYhBJ3UQghlJSUNGPGjFWrVpEtLxBCzZo1y8/Px12F0RAxIZFIli1bdvz4cdzlkAL0Mt5twYIFBQUFO3fubN++fceOHXGX86/Nmzc/e/YsISEBdyHv5uLiYpSb90lFIBDExcURiwZevny5R48euCvCCXoZ/yMxMZG4CPLxxx/v3LmTWH8Bd1H/ioyMZLFYq1atwl1IrYgTE9xVmETLli2J+AgODi4rs97dsCEyEEKIGNFctmzZ7du3iTsRevXqhbuo/1FWVta/f/8RI0ZU371OTj4+Ppa9Ilb79u1v3rypUqmUSiVJBrbMzNpPTBQKxdq1a11cXIibHc0/C6su/vrrr4ULFx48eLB67SnSYrPZ+fn5eXl5Li7GXC+HVOh0upOTk16vP3r06KNHj0ge4kZnvb2Mhw8fEtuXBgQEED91cuZFXFzcrl27kpKSyJ8XBE9PT+LkzrLRaLT169eHhIQQV99xl2M+VhoZERERBw8eRAi1a9duyJAhuMup1cqVKwsLCzdv3oy7EAN4eHi8evUKdxVmQlxSsbGxCQkJIe2N/8ZlXatyHT58uFOnTo0aNXr06BH5L7OPHj06IiLi448/xl2IYX777TepVErMv7YeCoVCJpPRaDSlUunu7o67HBOyil4GEYs//vjjixcviB8nyfPiyZMnwcHBS5YsoVxeENPn09LScFdhbjweTyKRCIXC6dOnX7lyBXc5JmThw59arXbTpk16vX727NmLFy+mxCr1Z8+e3bFjx82bN99Y84IqPDw8rGEs4504HM7JkyeJKylZWVl+fn64KzI+CvwJ1U9FRYVQKPz7779tbW2JTjIl8iI6Ojo3Nzc+Ph53IfVnzZFBIMZET58+rVKp5s2bh7scI6Pk59gH7d69e/DgwTQarVWrVhQ6qZ4/f75AIFi+fDnuQhqEz+cHBgZSaK0dE5k9ezZx/mthOz9aVGRUVlY+fvyYWOvl0qVLxBZhlCCXywcOHDhw4MDPPvsMdy1GUFlZmZubi7sK/IgVj54/f05srGsZau2rV1ZW4vqTEwqF9XjVzZs358+fHxcXhxDq37+/CeoylYcPH3755ZeHDx9u+MbuJOHq6pqbmxsQEIC7EFLo1KlTXl5eWlqav78/GZY1aaBaI0OpVOK6/mpoZJw6dWrgwIECgYCKM2pOnDhx4sSJq1ev4i7EmFxdXV+/fo27ChIZMmSIRqOprKzct2/frFmzcJfTIJQ/MenZsyfRG6LiZ1psbGxaWtru3btxF2Jknp6exMJWoBqTybSzs7O1tSU6wtRFgYsI70R0KHr27Hn+/HmKdvZmzpwZGhpqkXcoODo6Wt4t8EYxceLE4uJiYskv7Ku61Q8lexlnzpw5deoUsYwFFfNCoVB88skn48aNGzx4MO5aTMLFxcXCLhMYkYODA3Fz044dO3DXUh916mUUFhbWdqlSLBYfOHDA2FXVKj4+fuTIkYGBgf369TNbo8b1999/T5ky5ejRoxZ8r6ezszNExvtNmzaNmPFVVVXF4XBwl2OAOkWGQCAYP3488Tg9Pf3u3buffvopsSyC2e7+1Ov1wcHB69evJz7EzNOo0f3xxx8HDhyw+HUWbGxstFqtXC6Hndbfg5jxtWzZslGjRlFoJK5OkcHn80ePHk08jo+Pv3v37uDBg+3t7d9+pl6vN/ql2by8vOzs7LZt2966dYtCUy3eFhMTU1BQsG/fPtyFmENwcHBBQQGxaQN4j6VLly5evJhCkdHQsYyYmJgxY8bcuHFj8uTJAwYMuH///p49e2qeoj9+/HjAgAHVO1/ev38/MjJyyJAhERER69at++Acwdzc3MmTJ/v5+dHpdErnxYIFCzgcTlRUFO5CzEQmk8FFkzoiJnolJSXhLqROjDD8KZfL9+7dO2PGjMWLFxMbQNQmNTV18eLFjRo1mj179tChQx8+fLhw4UKlUvnOJxcXFyuVSp1Ol5iYKBaLG14nRmPGjOnTp49VbYrh4OBAXBoAdeTs7Dxz5kzcVXyYES6yqlSqWbNm1eV28i1btvTv33/69OnEl23btp06derdu3e7dOnyxjPv3LmzcOHCM2fOeHh4NLxCjAoKCoYNG7Zjxw6SbGhgNvb29nCbiUECAgIocT+UESKDw+HUJS/y8/NfvnyZm5tL7HhcrbCw8O0nP3ny5Ny5cw2vDa/U1NSFCxdeuHDBslfQfScvLy+5XI67CooJDg5GCG3btm3KlCm4a6mVESKjjhdNiJ2ExowZ07Vr15rHaw6j6vV6mUzm5OQ0cuTIhheG14kTJ9LS0v744w/cheDBZrMzMjJwV0FJERER/fr1e+OTlTyMP/uztkFK4s6RqqoqT0/P2l5bWVlZv3vSyGbTpk0lJSWLFy/GXQg2YrHYmjf7aAg2m03avDDJ7E9bW1u1Wl1RUUF8Wb3dnru7u5OT0/nz5xUKBXFEo9FU7xJOPBCJRBRdiqqmRYsW8Xg8a84LiAyjWLBgAQmX5jX+32dQUBCNRtu6dWtmZuaFCxeqV8em0WhTpkwpKSmZM2dOYmJiQkLCnDlzTp8+TQygVmcH1U2YMKFHjx6TJk3CXQhmdnZ2xKkoqLeoqKjZs2fjruJNxo8MLy+vOXPmPHr06Ntvv01OTq75x9OlS5eoqCgWi7Vt27ZDhw45OTkRM1i0Wq0FTBOUy+VjxoyZP38+Fdf4NTpbW9vq7iSoHy6X++uvv+Ku4k21bkpQWFhohk6RXq/X6/VvnIxQZY+fmrKysj777LPExERbW1vctZCCRqMJCQm5ceMG7kIoLyMj4/z58+SZsoFz4ECtVldWVlrA4EVKSsp333139epVyItqTCaTwWDUNk8P1J2/v7+/v//evXtxF/JfONfLoNPpIpEIYwFGceTIkWvXrh0+fBh3IaQjFAqlUqkVzkkxutDQUNwl/AvbJ7xWq2UwGLhaN5YNGzY8efKEuL8WvKFp06YymQx3FZZj7dq1ZLhtB09kSKVSjUaDpWkj+vHHH+3s7BYsWIC7EJIqKSmBEVAjmjhxIhlGNDBEhlarZbPZ1FpW5G2ff/55t27dJkyYgLsQ8uLxeDCWYUQSieTQoUO4q8ARGQwGg81mm79dIwoLC/vqq6/69OmDuxBS43K50Mswuhs3blRPj8Si1uFPOzs7U1zLuHjxYkFBQXh4uNHf2TyKiooGDBiQkJDg6uqKuxay8/DwsIDTT7Jp1qzZ8OHDMS6uUWtkmGgH03Xr1u3YsYOiF1b/+eefyMjI69evW8DArRlIpVIY/jQ6sVi8Z88ejHtEm/Uiq06nS0hIoMR2ym+7fPnynj17yHy/ENmw2eyqqircVVggvIvImPXTvqCggKLjYUePHk1ISNi5cyfuQqiEw+FAZJhISkrK3LlzsTRt1siIiIigYmTExMRkZWX98ssvuAuhGIFAQMIbMS1DSEiIh4dHZmam+Zs23zlCQUGBj4+PRCIxW4tGsWHDBqFQCJMv6kGn01HxE4IqIiMjsbRrvl6Gk5NT9Y3wVDFr1ix/f3+rWubXiBgMhlarxV2FJUtKSjL/BVfzRUZxcTG1dgMfN27cqFGjqLstG3ZisRhuMDEpDoezYsUKMzdqvhOTS5cuZWVlUaWH369fv/Xr19dlGWRQG4VCYTErJ5FTSEhIVVWVVCo15/KX5osMe3t7SgxklJWV9e3b9/Tp046OjrhroTYmkwljGabWu3dvM7dovhOTjz76aPLkyWZrrn6ePn06fPjw69evQ140HJ/PhxMTU9NqtWb+szJfZKjVajLcuvset2/fnj9/flJSEkzuNAqiz4y7CgvHYDBcXFzMOcPQfCcmLBYrLCwsJSWFnLM/k5KS4uPjjxw5grsQAAwTFRVlzjEjs07lCgkJSUtLM2eLdXT48OE///xz69atuAuxKAKBgOqb6VICk8k0563hZv3AX7NmjTmbq6OtW7eWl5db+bYjpiCXy2FfAvNYunRp+/btw8LCzNCWWXsZMpns1q1b5mzxg1auXEmj0b799lvchVggDodD9YVRqKJPnz6pqanmacuskSEQCNauXfv8+XNzNvoeK1eubNy4MZm3zKU0tVoNF1nNIyQk5PvvvzdPW7XuY2IiN27cYDAYS5YsKSgosLOzO3v2rDlbr2natGnh4eE9e/bEVYClGjp0qFKp1Ol0CoVCr9cLhUKdTqdSqS5duoS7NEuWk5Pj4OBghqvaZh3L6N+/f1FRkU6nI7Z6ZjKZ5eXlWPb+CA8Pnzt3bnBwsPmbtnienp4pKSnVqygRa/n5+PjgrsvCHT9+XCgURkREmLohM52YfPkCRhDLAAAfnUlEQVTll126dCF2YCPyQq/X29jYYMmLIUOGLF26FPLCREaNGvXGfnccDmfMmDH4KrIK3bt3r9473aTMFBkxMTG9e/euORhGo9HMv3ymQqHo0qXL9u3bmzRpYuamrUfXrl2bNm1a84i7u/vQoUPxVWQVWrduPWvWLDM0ZL7hz6VLl/bs2bNmari7u5utdYRQXl5eaGjopUuXYDK4qYWHh1fvg8dms0ePHo27IquQlpZmhmXQzHrFZPny5T169KhOjUaNGpmt6UePHk2ePDklJYXq+6dQQpcuXfz9/YnHnp6e0MUwj507d5ph32xzr/S9YsWKXr16sdlssVjs5uZmnkZv3ry5dOnSxMRE8zQHEEJjx44ViURsNpu6G1BQTo8ePcxwU4/BV0zKC9WI1qAmv42MomkEjx8/FgvcyotMPjc+PT09Pj4hZsPu/2+LJrRlMFgN+z+Yl0qpU0gptrxVq2YdWzYNLisr+6hbmBl+ysbF4tL5Qurdmjh48GAztFLXeRkVxeo/E0uePKj0aiYseU2lZaO1Wg2D8W8ysrn0skKVkwe3TQ9bv0DzLUxSP/eSy+5fLiNGi3HXYkW4ArqsXNOys23H/va4azGATCZ79uxZQECASVupU2SU5mtObM7uPdrN1pFNp174voO0THPrTJFfG0GLTja4a6nVleNF6irUorNYKCbjvb+WTV6pffawsjhX+cnnLrhrqauysjIzbKT24bGMihLNiZjsEZHedi4WkhcIIaGY2Svc5Vm67GFKOe5a3i35SCGNRu/QXwJ5gQXfhtGyi9jFh58YS5kFa8VicVBQkKkvmny4l3FuX37TYDsHV8u8vyjpQG7/CBcOj1wbPuY9r3qQUt55oFMdngtM6875Iq+mPN/WAtyFkMWH/1Sy7lfaObHMUgwGWrW+MJt0QzOF2UoaHQYvSIHNZeS/oszNdQ8ePCgpKTFpEx+IjPJCtae/kM6w2F9fZ29ueZEKdxVvklVqHNxh1UxSsHflKGU63FXU1ZEjR0w9NeND58k0VJpHug9hI6qS67Ua0m0CqFLo6QyKXVW1VFq1Xl6hwV1FXXXo0KF63q2JwNAaAJZj4MCBpm6CXMN+AICGePnyZXp6ukmbgMgAwHKkpaUdOnTIpE3AiQkAlsPHx6e4uNikTUBkAGA5mjdv3rx5c5M2AScmAFiOsrIyUy81Dr0MAMiirKxMpWrQLCGNRsPn8wsKChpYiUQiqV699Q3QywDActDpdBbLtHO1ITIAsBx0Ol0gMO3tMBAZAFgUU2/pDJEBgOXQ6XSmXsuPFJGh1WofPvyfYd6nT7MGDe6Vci0ZX1GWQCqVPs58hLuKN2VmZfTq3f769auGvlCn0+3YGTNiZL9BQz66cSMFIVReXrZ02aKBg3qGjwkrKTHtfAQspk+fPuAt9+/fr+35FRUVY8eOPX36tOlKIsUVk9Vrl2Zk/L1rR3z1ESaTKRTaMBmkKI+6Jk8J79ypW9MmzXAXYhyJp48fPLRn6pRZnh6NAgICEUK/blx1/8Hdr79eKBAI7e0dcBdoEq6urn369Kl5xMWl1oXCzLDgIyn+JlVvrSPk5eV9YP9JTOVYjvdfsaveuY4q/rr1Z9ug4E9HjK15JHzUxN4ffWzQ+1DrP+7k5ESqjWCMHxkPH6bui4t9mJaKEGrm33LatK/9m/53OppSqdwXF3vp0rnCogJnZ9e+oZ+MHfPZ6rVLLyWfRwj16t0eIXRg/8n79+/8Z9UShNDqVZvat+uIEPr7n7QtW9dnZPzN5fK6dO4+fXqkyEaEEPr+h7meHo2YTGbi6eMatbpTp5DZsxYIhWRfBNgUDhzcfSIhvrKyws/PP2Li1HZtO4SPCSstLTmRcOREwhFnZ5dDBxLLy8uGDOszberszKyMa9eSmzRp9uv6WIRQwsmj8UfiiooKXFzcen/Ub9TI8RwOR6VS7d23/eLFswWF+Q4Okr6hn0RMnMpgMBBCAwf3/GrGvKRLZ+/duyUU2vTp3b9166Bdu7dkZ7/08W4cGbmo+if+HheTz23ZtiEvL9fPz3/qF7Natw5CCN2+c3PetzM2bdzVokUr4mn9PwkZOmTUlC++6h3aQafTEb8nX82c18TPf9bXkxFCsTs2xe7YtGP7IV9fP4TQvdTb22Ojnzx5bGdnHxQYPPnzGQ4OEoTQZ5+P9PFu7O3d+NjxQ1wu99ABau9QUVhYuHfv3tu3b8tkMnd391GjRhEbkhPfomrZ2dnR0dEZGRk2NjbBwcEzZswgZlucPn362LFjxcXFzs7OPXv2HDZsWN339zF+ZOTl5VapqsaPm0yn0xMSjixYOOvg/lNcLler1S767uuHaanDhob7NW76/MXTV9kvGAzGuDGTCgvyX7/OWbjgJ4SQg70kKDB4yhdfbdu+kXjD58+fzv1mmrd342/n/VheVrpr95aCgry1azYT/xp/JO6jXn2X/7z+5Ytna35Z5uDgOG3qbKP/p0juzt2/tsdG9+7dr2Nwl79u/amQyxFCUT+u+nb+zMA27T4dMZZVY5O6uLgdgwd/unbNFuLvf/eebUeOxg0bGt6oke+rV88Px+/Nznm5aMFPDAbjzp2bnbt0d3P1yMrKiNu/08ZGNPLTccSbrF3385fT50RMnHr48N4jR/dfvHR2buR3XB5v/YaVS5bM37vnGJP5gV+t58+ejBg+Riqt/O3Ywbnzpm9Yt706Jt7pp6jV22I3cticCRO+8PVtIhAIl0St+jHq29DQAd27feTs7Ep8HxYsnBXaZ8DQIaMqK8p/O3ZwzjfTtm6OI/ZDv3XrurJKuXzZOlNfUzAujUZTWFhIPGaxWGKxmDj4+PHjAQMGiESiP//8c9WqVa6urv7+/m/0njZs2JCdnT116lS5XP7gwQMiL/bv33/s2LFBgwZ5eXllZ2cfPXo0Jyfnm2++qWM9xo+MPn36h4YOIB77+7eYM3faw7TU4PadLl9Jupd6e943iwf0/5/dFjw8vGxtxSWlxa1aBRJHnJ1d2rRuW/2EuP076HT6qv9E2whtEEI2NqLlK3+4f/9umzZtiZcvWriURqM1b9bySsrFW7evW2Fk5OXlIoSGDh7ZsmXr6m9+M/8WTCbTwUFS/Y0ltGjRavLnM4jHRUWF+w/s/P67n3t0700ccXBwXLd+xcwZ34hsRDGb9lT/Cua+zr5y9WJ1ZPTvN2jwoBEIoalTZ1++kjR2zKTOnbshhMaO/mzFf37Mzc328vJ+f82TPptOvCS0z4CISSNid2z6Ze2W9zy/a9ceh+L38ri8kK49iSNdOndHCHk38q0+sjF69cCwYbO++pb4sn37ThM/G3Hr9vVuIb0QQgwmc/F3y3k8noHfXczS09MnTpxIPG7RosWaNWuIAY4tW7YQP52+ffuOGTPm+vXrb0dGfn5+48aN+/XrhxAaNmwYQqi4uPjw4cPffvttSEgI8RwHB4fo6OipU6fa2NRptX3jRwaNRruacin+SNyLF8/4fD5CqLSkmDjt5HA4H/cNM/QNU+/fCQoKJvICIRQc3BkhlPH4byIyuBxu9bfJ2dk1La3WwWQL1qljiI2NaPmKxV/NnNepU8j7n9y2bYfqx3fu3NRoND8v//7n5d8TR4jlo4sKC0Q2otLSkr37tt+6faOysgIhVP0jQAhxOP9dZ5DNYhMbrxJfOjo5Excy6l68ROIY0rXXhaQ/NJoGLX6Vl/f6xYtnOTmvEk8fr3m8oCCfeNC8eQDl8oK4OXXChAnE45p/1U+fPo2Li8vMzCSuOZaVveN7/tFHH8XHx2/evDk8PNzOzg4hdO/ePY1Gs3r16tWrVxPPIX7ixcXF2CJj777YXbu3DB82esrkr4pLipb8tECn1xHBIXFwJDrDBpHJpGJbu+ovbWxExMfj289kMVk6nTWuf+fgIIn+deemzb8s/O7rgIA2P3y/wtGx1tXJudx//2yKS4oQQst/Xu/k6FzzOW5uHiUlxVOmjeXx+JM+m+7m5rFzZ8yr7Bcmqt/R0Umr1SqVDVqVt7S0GCE0ccKU7t0+qnnc3l5CPOBxqZcXCCGRSNSxY8c3Dqampv7www+tW7eOjIzk8/nLli0jRjHeGMuYOHGiWCw+fPjwuXPnJk2aNHDgQGIx4aioKIlEUvOZrq6udazHyJGh0WgOHNz1yYAhM2fMrRnwCCGh0KaktNYr5+/ZG0Eicaqo+He3kdLSEuLdjFo45Xl5ef9nxa9379364cdv/rMqas3qGOL4+zedIPKXePkb/3Ty1G+lpSWbNu52dnZBCDk5uZguMkpLS7hcrkAgaMiFDOJXoqpK+cFzIgtw6NAhV1fXqKgoYsyIGKx5+yIrjUYbMmRI3759N27cuHnzZl9f3+quhKenZ/2aNvJULpVKVVVV1fT/B8zLK8qqky8oKFihUCRdPFv95OqOKJfLKykpfiMgq7Vs2Tr1/p3qj6ArV5IQQm+cnwPiemrboOBOnbpVT9/icXnFxUXveVVQUDCNRjt+4nD1EYVCQTyoqCgTi+2IvCB+lHXci9NQSqXyxs2UwMD2NBrNTmyPECoq/m8Xsri4qO5DlR4eXs7OLn+cOVn9X9BoNNQa6ay78vJyX19fIi9UKpVCoSD+fIgzxMrKSuJpxDZIfD5//PjxCKGsrKw2bdrQaLSTJ/+dwVD97aojI/cy+Hy+r6/fseOH7O0dZFLpnr3b6HT606dZxCjXiYT4lf/58dGjdL/GTZ8+y7pz9+a2LfvpdHqb1m3/OHPyl3XLWwUE2tiIunTpXvM9x42ZdPHi2fkLvxoYNrygIG/P3m1Bge0D27QzbuWU9s+j9CU/zR8yeCSPx//rrz+b+bcgjrdqFZR08cyBg7ttbEQtW7QmLjfW5OHuOWxo+G/HDi76PjKka8/i4qITCfErlm9o2qRZYGD74yfid+7a3LJlm6tXL968eU2n05WXl9naio1Sc+zOTSWlxXK57MzZUxUV5RETpxKdHWdnl7i4HXZie7lCvmPHpto+SN5Go9FmfDn3hx/nzfgqYtDAETqt9uy5xNDQASOGjzFKwaTSpk2b8+fPnz17ViQSHT9+XCqVvnjxQq/X8/l8V1fX48eP29ra9u/ff8WKFXw+v23btrdu3UIINWnSxM3NbdCgQQkJCVFRUZ07dy4tLT116tSSJUv8/Pzq2LTxJ4wv/m45j8v7aenCw0f2TZ8eOX7c52fPnlKr1RwOZ+2aLR/3DTt/4ff1v67869af3bv1JjoaoaEDhg4ZmXz5/LbYjel/P3jjDT08vFatjFar1atWLzkcvy+0z4Cflqyh0FQcM2Cz2I28fA4c2BUbG926ddA3cxcTx6dOmRUU2H5fXOyBA7tycl+987UzvpwzfdrXz55mrVu/4vTvx7uF9HKUOCGEunf7aML4yScSjvz883dqjXpT9G4vL++a/ZGG8PLyDunac19c7I6dMUKhzS9rthBTOZhMZtSPqxhM5rz5M7Zt/3XC+C/qPl8AIdQtpNeKn9ezmKxNMWv3xsU6O7u2rnHpzZKMHz++Xbt2W7du3bx5c1BQ0KJFi0pKSu7fv6/T6aZPn+7m5nbhwgWEkL+/f0ZGRnR0dFZW1qxZs1q0aIEQmjJlyuTJk1+8eLFp06YzZ8506dLFwcGAibMf2GCxvEidsDl36KxGxvhvktFffxQ5ujNbdzPOJ6exXDlWxBUym3ckV1XW6eU/sudpFZ9MruvoYEM0fIkdnU4nl8sbPpvxPUvskGLCOLA822OjT546+vZxkY3t/rgEHBVZBTqdburZzxAZwCRGjhwfFjbs7eN0GilunrZgGo3mg1NvGwIiA5iErcjWVmSLuwqro9VqKysriVlbJgKRD4DloNFo7Br3E5kCRAYAlgPW/gTAijR86oBOp6t6a/UZ41YCYxkAkIWtbUNHf1JTU6Ojo2NjY41U0TtALwMAyyEQCNq2Ne3sNehlAGA5mjRp0qRJE5M2Ab0MACxHWVnZkydPTNoERAYAluP69eu7du0yaRMQGQBYDoFA0LRpU5M2AWMZAFiO7t27d+/evQ5PrL8P9TL0NHtXA+4+phwun87iGLy2oKlxBWSsyjoxWDShmDKfrK9fv87NzTVpEx+IDFtHZvZjmUZlkuWYyCD3qVwsYeGu4k0CEbPwlWFrJQETKcpRcgWUie/9+/dfvnzZpE18eCyjSVubknwjzCcjJyaL7uTFxV3Fm5w9uTqtxcY0tagUOhdv0v2G1MbNza3u62vVz4cjI2Sw5EKcabs6uJyPy23ZWUTCjV8lHmxbCfNG4jtWUQfmdD+5VKfRNmrOx11IXY0ZMyY4ONikTXxgVS6ColK7+6fnH4W72TqyBLbk+wszkEqpKy9U3T5X1GmAvVcz8v423LtUlvtE2ayj2MGNw2DCwoXmo9ej4tyqF+lSGl3XY7gj7nIMkJKSEhAQQOyoZiJ1igyEkFatTzlZ9CxNJnJgFb5q0H4TeLF5DHWVzqMpr20vO/J3OLNSpamXyypK1GplXVfNJQ+9Tq9HiE6nXtgJxSwWh9ayk23LLiLctRgmLCxs+/btdd+UpB7q2mVgsGg9hjv2GO6orqL2ObYeITaHMr/EfoFCv0AhQoiK3/b4+Pi8vLxZs2bhLsRgTDZVl6MODAx0dDRtt8jgswwWdf7eLAkVv+00hhbRNVSsnLqWLVtm6iZg9icAFkImk92/b/I9iSEygKnweDxTr3YNarp582ZcXJypW4HIAKaiUCikUinuKqyIXq/v2rWrqVuh/BVTQFp8Pr/hy0yBuuvdu7cZWoFeBjAVvV6fl5eHuworkpqaWl5ebupWIDKAqYhEIpGIYvMaKG327NkMhslvh4HIAKbC5/MfP36MuwprUV5ePnLkSDOMN0NkAFOxt7c3ygL5oC5sbW1nzJhhhoYgMoCpuLm5ZWZm4q7CWty4ccMMkzIgMoAJ2djYsNns4uJi3IVYhU2bNrFY5lj5BSIDmFBISEh2djbuKiyfRqPp3r17ixYtzNAWRAYwIUdHx1u3buGuwvIxmcwvvvjCPG1BZAATCgoKunfvHu4qLN+lS5fS09PN0xZEBjCh4OBgmUyGuwrLt2TJEi8vL/O0BZEBTIjBYLi4uFy4cAF3IZasqKho1apVNjY25mkOIgOY1scff3zmzBncVVgyiUTSoUMHszUHkQFMq1evXvn5+XK5HHchlkmpVJpt4JMAkQFMrnfv3jt37sRdhWU6dOhQu3btzNliXZcLBqAh2rdvf/v2bdxVACOAyADmsG/fPq1WGxERgbsQi1JWVqZSqZycnMzZKJyYAHMYP378b7/9ZurtQq1Nv3797OzszNwo9DKAmdy+fTs2NnbLli24C7EQycnJHA6nc+fOZm4XIgOYz4YNG3x8fAYNGoS7EFB/cGICzGf27NlHjx4129RmC7ZmzZoXL15gaRp6GcDc2rdvf+vWLaruR0YCBw8elMvln3/+OZbWITKAub18+TIqKgpmalAUnJgAc/Py8po3b964ceNwF0JJ27Zt02g0GAuAyAAYNG/e/Ouvvx4/fjzuQihmwoQJXbt2ZTJxbj8EJyYAm9LS0sjIyN27d+MuhBrkcjmTyWSz2XjLgF4GwMbOzm7u3LlDhgzBXQgFpKWlZWdnY88LiAyAWatWrTZu3Dh58uSysjLctZBXbGxsSkpK06ZNcReC4MQEkEJlZeWQIUPWrl0bGBiIuxbSqaio4PP5eMcvaoJeBsDPxsYmKSkpOjo6MTERdy3ksn79ejqdTp68gMgAJBIbG5uRkfHzzz/jLoQsbt++LZFIzLBnokHgxASQy7Fjxw4dOrRz506y/amYmVarzc7ObtSoEe5C3gS9DEAuw4YNW7FixeDBg5OTk3HXgkd5eXm3bt0YDAYJ8wJ6GYC85s6d6+jouGDBAtyFmNvevXtHjBjB5/NxF/Ju0MsAJLV27drGjRsPHz7cerZoXLlyJTHFk7R5AZEBSO3TTz9dv379zJkz9+/fj7sWk/vxxx/Ns6lqA8GJCaCAX375pays7Ntvv7XIMdG7d++2bdu2qKhIIpHgruXDoJcBKGDOnDlDhw4NCws7efJkzeO9evWKi4vDV5fBBgwY8MaRadOmEXtQUiIvIDIAZQQFBSUnJ9+7d2/+/PlqtRohNHTo0MrKyvj4+IqKCtzV1cnq1asLCwtDQkKILx8/fkxERrdu3XCXZgBGVFQU7hoAqKuePXvyeLzRo0d7enqeOHGCmGxeVVXVpUsX3KV9QGZm5ubNm2UymUajOX369LVr1xo3buzp6eni4oK7NMPAWAagpM6dOxN9DYSQo6Pjpk2bfH19cRf1PnPnzr18+TLxWKfTxcTEdOrUCXdR9QEnJoB6RowYUZ0XCKHCwsJNmzZhregDUlJS7t27V/0lnU7/5ptvsFZUfxAZgHreXlw7NTU1JSUFUzkfFhsbW15eXvOIUqkcOnQovorqDyIDUMyYMWPs7e3t7OwEAgFCiDizLisri4mJwV3aux09ejQzM5MoVa/Xc7lcsVjs6OiIu656grEMQEnPnz8vLCx8/ao0O0Ojlgr1Kj7Ssl3dJSV5Ctyl/Q+OgCmrlGlRFWJU0XmVDl4azyYCBwcHJycniqYGie7DB6DuZK/tH19myCokYolA6M5jMOksDoPJZjqSYuWqf9FoSKPWaVRaTZVGrdRWvJb+/VjVvKNtY29z76VqLNDLABTz5IHsyvEijpBj72nLtcG/FqahtGpdZZEiL6PIv72o16fUmL5VE0QGoAytFiXuyK8s0zn62nEELNzlNFTR83JFmbx3uLObD5X+LxAZgDLiVr4SSGzs3G1wF2I8epR1PbvnCIlfGwHuUuoKIgNQw8E1OWJPe56IemciH/TyXl6fcImbLwd3IXUCF1kBBcSteGlnoXmBEPIKcrlwsDDniRJ3IXUCkQHI7vdd+TbOtlwLzQuCV1vXU9tyqxQ63IV8GEQGILXHd6XSSmTraoHLZLzBu63r6R15uKv4MIgMQGpXTxTZeYpxV2EOXBFboUBPHshwF/IBEBmAvO5fKRfY81lca5lwKPGxv3qiCHcVHwCRAcjr4Z+V9l62uKt4h6LiV98s7njvwTnjvi1HwGLx2K8eyY37tsYFkQFIqjRfrVJo2Txr6WIQeLbcx6mkPjeByAAk9fShVCAh79r8JiJyEjxLk+Ku4n2sK8IBhRTmqoX2ppoT+edfv12+dqC8osDezi2odd+eXcexWJyc3Izo2C8+H7/u93MxuXmP7cSun/SdGdC8O/ESqaw04fd16Y+usJicxj7tTFQYk8OwceCW5qntXEg6ixx6GYCkCrOVDJZJfj/PXdx++mx0YKvQkUO+b92yd/LVuKMJK4h/Uqur4g5/171L+PRJm+3ELgeOLJbJyhBCao1q6+6v0v+53L3LmE8+nllSmmuKwggqpVZWqTHd+zcQ9DIASSkqNSyO8X8/yysKk67sHjtiaeuAj4gjtjaS3079Z/CAOcSXQz6ZG9gqFCE0IPTL9ZsnPnl+r3XLXtduHHmdlzll4samfh0QQt6erVb9OsrotREYbKasAiIDAEPotEhoz2awjd/LyHzyl1ar2X/0h/1Hf/j/Y3qEUHllAfEFm8UjHtiJXRFCFZWFCKG0fy67OvsReYEQotMZRi+sGlvAVivIe+cXRAYgIzoDVRRWuWj0dCbNuO9cUVmEEPp83C9iW6eaxx3sPfLyn9Q8wmSwEEI6nRYhVFae5+7qb9xKaqOSq+ks8v5hkrcyYOW4Qqa6SsNhGnkUkMcTEQ+cHL3r/iqhwE4qKzVuJbXRqjQCEXn/MGH4E5CUUMzUqLRGf9smvu1pNFrKzfjqI1WqDy8X6u7q/yrn74LCN1c2NwWdRiewhcgAwEDOXhxFWZXR31bi4BnSadTfj67ujJt7887JC8k7V64bnp376P2v6tVtAo1Gj9k57eKVPbfvnT6WuNrohRH0eiQtqZK4kfe2XfKGGbByjVsLn6YXSXyMP2F8UP+vxbZOKTeOZGTdENlIAlr0tBU5vf8lEgePLyZsSDz769mL28W2zq2a93ycddPohSGEKgpkXs1IfdsurMoFyGvL/KdNQjwZTCvqC+emF7brKfBvT97FCqGXAcirRWfbotcye89a/36OJ665c/+Pt497uDbLfv3uc42vvoh1dvIxVoW/n4/586/f3j7OYnLUmnefVf0w7zSbzX332+lRlbSqaTtSb+wMvQxAXjqtfvO3T1r2qfUvXCYrq1K9475PGq3WX2xbkRODYbRPSpm8vKrqHXeRaTRqZi3XeuzErjTau68c52eW+LVgtetD6vVBIDIAqd34veTVM52jL1U3Cqo7rVqXdf3V1BWk3r8erpgAsus0wF4jV6oU5J1AbSyFWUX9xpP6lIQAkQHIbmSke+a1V7irMK3CJyV+rbiNWlDgZn+IDEB2DCZt7IJG2fdf4y7EVPIfl3g2ZrUPpcbJF0QGoACxI2vQFy6Pkl+olcafD4pX/uNiR1dap/6kHvKsCYY/AWVUKXRxy1/aeYrfc9mVQpSVqoq8iqZtuIE9yLi+aW0gMgDFJB8pfnyvwsnPXkzZzU3USm1BVrFOre4d7uTmW8scDbKCyADUIy3TJP9WnJMlEzrwbRwFQgcenWHke+SNTq9DKoW6PE8mK5bZ2LNad7Vp2paSkQeRAaiqSq57mibNuCOTlmkqilRsHkPkxFNUqnDX9T9YHIZSqlEpNFqNztmL79aY69dG4ORJjR2b3wkiA1gCrVovq9AqpBqtlly/z3REY/HoAlsml28hlxogMgAABrCQ5AMAmAdEBgDAABAZAAADQGQAAAwAkQEAMABEBgDAAP8HT7zXxKFFCQgAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(abot.graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received chunk: content='' additional_kwargs={} response_metadata={} id='run-2f406a60-6dec-4ca0-8127-7e60300e9f86' tool_calls=[{'name': 'search_chunks', 'args': {'k': 10, 'question': 'latent space structure control in diffusion models'}, 'id': '865e6f56-8c17-460c-b3af-3b09e1c5f25f', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'search_chunks', 'args': '{\"k\": 10, \"question\": \"latent space structure control in diffusion models\"}', 'id': '865e6f56-8c17-460c-b3af-3b09e1c5f25f', 'index': None, 'type': 'tool_call_chunk'}]\n",
      "\n",
      "\n",
      "\n",
      "metadata: \n",
      "{'thread_id': '2', 'langgraph_step': 16, 'langgraph_node': 'llm', 'langgraph_triggers': ['start:llm'], 'langgraph_path': ('__pregel_pull', 'llm'), 'langgraph_checkpoint_ns': 'llm:336ad963-4b9f-9d61-2e86-f5fbd229a01d', 'checkpoint_ns': 'llm:336ad963-4b9f-9d61-2e86-f5fbd229a01d', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.3', 'ls_model_type': 'chat', 'ls_temperature': 0.5}\n",
      "\n",
      "\n",
      "Calling: {'name': 'search_chunks', 'args': {'k': 10, 'question': 'latent space structure control in diffusion models'}, 'id': '865e6f56-8c17-460c-b3af-3b09e1c5f25f', 'type': 'tool_call'}\n",
      "The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "8. **Diffusion Steps Reduction**: Reducing diffusion steps to improve speed while maintaining high output quality.\n",
      "9. **Few-Shot Learning**: Restricting data and domain for few-shot learning to adapt to new environments with limited training data.\n",
      "10. **Smooth Latent Space**: Investigating the latent space smoothness for diffusion models, which can be used to manipulate generated images and enable applications like image editing.\n",
      "11. **Latent Space Disentanglement**: Exploring latent space disentanglement to separate factors of variation in the generated images.\n",
      "12. **GAN-Inverse**: Using GAN-inverse methods to find the latent representation of a given image, enabling image editing and manipulation.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.search_document: 2022; Hu\n",
      "et al. 2023c) has played a significant role in driving these\n",
      "advancements, prompting further investigations into the understanding of the learned latent space and its potential use\n",
      "for image editing tasks. While current works perform latent\n",
      "space editing on the original latent diffusion model setting\n",
      "and architecture (Kwon, Jeong, and Uh 2023; Haas et al. 2023), not much is known about the structure of the latent\n",
      "space in the most recent advances in the field, specifically\n",
      "\n",
      "Copyright © 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.\n",
      "\n",
      "---\n",
      "\n",
      "search_document: # Understanding the Latent Space of Diffusion Models through the Lens of Riemannian Geometry\n",
      "\n",
      "**Yong-Hyun Park[∗][1], Mingi Kwon[∗][2], Jaewoong Choi[3], Junghyo Jo[†][1], Youngjung Uh[†][2],**\n",
      "\n",
      "1Seoul National University 2Yonsei University 3Korea Institute for Advanced Study\n",
      "\n",
      "## Abstract\n",
      "\n",
      "Despite the success of diffusion models (DMs), we still lack a thorough understanding of their latent space. To understand the latent space xt ∈X, we analyze them\n",
      "from a geometrical perspective.\n",
      "\n",
      "---\n",
      "\n",
      "search_document: 3. In practice, our Smooth Diffusion is trained on top of\n",
      "a well-known text-to-image model: Stable Diffusion [62]. We examine and demonstrate that Smooth Diffusion dramatically improves the latent space smoothness over its\n",
      "baseline. Meanwhile, we conduct extensive research across\n",
      "numerous downstream tasks, including but not limited to\n",
      "image interpolation, inversion, editing, etc. Both qualitative\n",
      "and quantitative results support our conclusion that Smooth\n",
      "Diffusion can be the next-gen high-performing generative\n",
      "model not only for the baseline text-to-image task but across\n",
      "various downstream tasks. ## 2. Related Work\n",
      "\n",
      "**Diffusion models are initiated from a family of prior works**\n",
      "including but not limited to [8, 66, 70, 76]. Since then,\n",
      "DDPM [24] introduced an image-based noise prediction\n",
      "model, becoming one of the most popular image generation\n",
      "research. Later works [12, 48, 71] extended DDPM, demonstrating that diffusion models perform on-par and even surpass GAN-based methods [15, 30–33]. Recently, generating images from text prompts (T2I) become an emerging field [11, 19, 28, 47, 62], among which diffusion models [16, 49, 59, 62, 64] have become quite visible to the\n",
      "public. For example, Stable Diffusion (SD) [62] consists of\n",
      "VAE [36] and CLIP [58], diffuses latent space, and yields an\n",
      "outstanding balance between quality and speed. Following\n",
      "SD [62], researchers also explored diffusion approaches for\n",
      "controls such as ControlNet [14, 26, 46, 57, 80, 85, 86, 89–\n",
      "91, 95] and multimodal such as Versatile Diffusion [6, 41,\n",
      "73, 88]. Works from a different track reduce diffusion steps\n",
      "to improve speed [5, 34, 39, 43, 65, 72, 92, 96], or restrict\n",
      "data and domain for few-shot learning [20, 25, 40, 63], all\n",
      "had successfully maintained a high output quality. **Smooth latent space was one of the prominent proper-**\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "ties of SOTA GAN works [9, 31–33], while exploring such\n",
      "property went through the decade-long GAN research [3,\n",
      "15], whose goals were mainly robust training. Ideas such as\n",
      "Wasserstein GAN [4, 17] had proved to be effective, which\n",
      "enforced the Lipschitz continuity on discriminator via gradient penalties. Another technique, namely path length regularization, related to the Jacobian clamping in [51], was\n",
      "adapted in StyleGAN2 [32] and later became a standard setting for GAN-based generators [10, 37, 87, 94]. Benefiting\n",
      "from the smoothness property, researchers managed to manipulate latent space in many downstream research projects. Works such as [7, 50, 68, 83] explored latent space disentanglement. GAN-inverse [1, 2, 52, 84] had also proved\n",
      "to be feasible, along with a family of image editing approaches [18, 53, 56, 60, 61, 74, 97]. As aforementioned,\n",
      "our work aims to investigate the latent space smoothness for\n",
      "diffusion models, which by far remains unexplored. ## 3.\n",
      "\n",
      "---\n",
      "\n",
      "search_document: Figure 1(d) illustrates some of these properties and § 5.3 provides detailed\n",
      "analyses. To the best of our knowledge, it is the first attempt to discover the semantic latent space in\n",
      "the frozen pretrained diffusion models. Spoiler alert: our semantic latent space is different from the\n",
      "intermediate latent variables in the diffusion process. Moreover, we introduce a principled design\n",
      "of the generative process for versatile editing and quality boosting by quantifiable measures: edit_ing strength of an interval and quality deficiency at a timestep. Extensive experiments demonstrate_\n",
      "that our method is generally applicable to various architectures (DDPM++, iDDPM, and ADM) and\n",
      "datasets (CelebA-HQ, AFHQ-dog, LSUN-church, LSUN-bedroom, and METFACES).\n",
      "\n",
      "---\n",
      "\n",
      "search_document: III. THE SEMANTIC LATENT SPACE OF DDMS\n",
      "\n",
      "Diffusion models are defined in terms of a forward diffusion process that adds increasing amounts of white Gaussian\n",
      "noise to a clean image x0 in T steps, and a learned reverse\n",
      "process that gradually removes the noise. During the forward\n",
      "process each noisy image xt is generated as\n",
      "\n",
      "_√_\n",
      "**xt =** _[√]αtx0 +_ 1 − _αtn,_ (1)\n",
      "\n",
      "where n ∼N (0, I) and the noise schedule is defined by {αt}\n",
      ". In [39], generating an image from the model is done by\n",
      "first sampling Gaussian noise xT ∼N (0, I), which is then\n",
      "denoised following the approximate reverse diffusion process\n",
      "\n",
      "**xt−1 =** _[√]αt−1Pt(ϵ[θ]t_ [(][x][t][)) +][ D][t][(][ϵ]t[θ][(][x][t][)) +][ σ][t][z][t][,] (2)\n",
      "\n",
      "where zt ∼N (0, I). Here ϵ[θ]t [is a neural network (usually a]\n",
      "U-Net [29]), which is trained to predict n from xt, and the\n",
      "terms\n",
      "\n",
      "**Pt(ϵ[θ]t** [(][x][t][)) =] **[x][t][ −]** _[√][1]√[ −]_ _[α][t][ϵ]t[θ][(][x][t][)]_ (3)\n",
      "_αt_\n",
      "\n",
      "and\n",
      "\n",
      "�\n",
      "**Dt(ϵ[θ]t** [(][x][t][)) =] 1 − _αt−1 −_ _σt[2][ϵ]t[θ][(][x][t][)]_ (4)\n",
      "\n",
      "are the predicted x0 and the direction pointing to xt at\n",
      "timestep t, respectively. The variance σt is taken to be\n",
      "\n",
      "\n",
      "(a) Effect of swapping the bottleneck activation. (b) Vector arithmetic in the semantic latent space.\n",
      "\n",
      "---\n",
      "\n",
      "search_document: Table 1: Details of redefining various diffusion models’ latent space (Section 3.1).\n",
      "\n",
      "---\n",
      "\n",
      "search_document: Method\n",
      "\n",
      "#### 3.1. Preliminaries\n",
      "\n",
      "**3.1.1** **Latent diffusion models**\n",
      "\n",
      "We adopt latent-based diffusion models (LDM) for our generation model. The diffusion process follows the standard\n",
      "formulation in DDPM [21] that consists of a forward diffusion and a backward denoising process. Given a data sample x ∼ _p(x), an autoencoder consisting an encoder E and_\n",
      "a decoder D first project the x into latent z via z = E(x). Then, the diffusion and denoising process are conducted\n",
      "in the latent space. Once the denoising is completed at\n",
      "timestep 0, the sample will be decoded via x = D( ˜z0). The\n",
      "forward diffusion is a fixed Markov process of T timesteps\n",
      "that yields latent variables zt based on the latent variable at\n",
      "previous timestep zt−1 via\n",
      "\n",
      "_q(zt|zt−1) = N_ (zt; �1 − _βtzt−1, βtI),_ (1)\n",
      "\n",
      "where βt is a predefined variance at each step t. Finally, the\n",
      "clean data z0 becomes zT, which is indistinguishable from\n",
      "a Gaussian noise.\n",
      "\n",
      "---\n",
      "\n",
      "search_document: We report more detail about mean and global direction in Appendix L.1. ##### 6 CONCLUSION\n",
      "\n",
      "We proposed a new generative process, Asyrp, which facilitates image editing in a semantic latent\n",
      "space h-space for pretrained diffusion models. h-space has nice properties as in the latent space\n",
      "of GANs: homogeneity, linearity, robustness, and consistency across timesteps. The full editing\n",
      "process is designed to achieve versatile editing and high quality by measuring editing strength and\n",
      "quality deficiency at timesteps. We hope that our approach and detailed analyses help cultivate a new\n",
      "paradigm of image editing in the semantic latent space of diffusion models. Combining previous\n",
      "finetuning or guidance techniques would be an interesting research direction.\n",
      "\n",
      "---\n",
      "\n",
      "search_document: ### 3.2. ControlNet for Text-to-Image Diffusion\n",
      "\n",
      "We use Stable Diffusion [71] as an example to show how\n",
      "ControlNet can add conditional control to a large pretrained\n",
      "diffusion model. Stable Diffusion is essentially a U-Net [72]\n",
      "with an encoder, a middle block, and a skip-connected decoder. Both the encoder and decoder contain 12 blocks,\n",
      "and the full model contains 25 blocks, including the middle\n",
      "block.\n",
      "\n",
      "---\n",
      "\n",
      "search_document: VI. DISCUSSION AND CONCLUSION\n",
      "\n",
      "We presented several supervised and unsupervised methods for finding interpretable directions in the recently proposed semantic latent space of Denoising Diffusion Models. We showed that the principal components in latent space\n",
      "correspond to global and semantically meaningful editing\n",
      "directions like pose, gender, and age. Additionally, we proposed a novel method for discovering directions based on\n",
      "a single input image. These directions correspond to highly\n",
      "localized changes in generated images, such as raising the\n",
      "eyebrows or opening/closing the mouth and eyes. Although\n",
      "these directions were found with respect to a specific image\n",
      "they can be transferred to different samples. As our proposed methods enable high-quality editing of\n",
      "face images, we provide a broader impact statement in SM\n",
      "Sec. G. Although our unsupervised approaches are effective\n",
      "in discovering meaningful semantics when the DDM was\n",
      "trained on aligned data like human faces, we found that\n",
      "models trained on less structured data have less interpretable\n",
      "principal directions. We refer the reader to SM Sec.\n",
      "\n",
      "\n",
      "metadata: \n",
      "{'thread_id': '2', 'langgraph_step': 17, 'langgraph_node': 'action', 'langgraph_triggers': ['branch:llm:exists_action:action'], 'langgraph_path': ('__pregel_pull', 'action'), 'langgraph_checkpoint_ns': 'action:00bd7ef9-e1d6-eb14-b0ea-c316d28290a0'}\n",
      "\n",
      "\n",
      "Received chunk: content='The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\\n\\n1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\\n2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\\n3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\\n4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\\n5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\\n6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\\n7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\\n8. **Diffusion Steps Reduction**: Reducing diffusion steps to improve speed while maintaining high output quality.\\n9. **Few-Shot Learning**: Restricting data and domain for few-shot learning to adapt to new environments with limited training data.\\n10. **Smooth Latent Space**: Investigating the latent space smoothness for diffusion models, which can be used to manipulate generated images and enable applications like image editing.\\n11. **Latent Space Disentanglement**: Exploring latent space disentanglement to separate factors of variation in the generated images.\\n12. **GAN-Inverse**: Using GAN-inverse methods to find the latent representation of a given image, enabling image editing and manipulation.\\n13. **Image Interpolation**: Using the latent space to interpolate between different images, creating new images that combine features from multiple sources.\\n14. **Image Inversion**: Using the latent space to invert the generation process, allowing for the reconstruction of the original input image.\\n15. **Quality Boosting**: Using the latent space to improve the quality of generated images, by manipulating the latent variables to produce more realistic and detailed images.\\n\\nThese methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.' additional_kwargs={} response_metadata={'model': 'llama3.3', 'created_at': '2025-02-26T06:09:48.464075467Z', 'done': True, 'done_reason': 'stop', 'total_duration': 41871283019, 'load_duration': 35706453, 'prompt_eval_count': 8250, 'prompt_eval_duration': 3064000000, 'eval_count': 516, 'eval_duration': 38647000000, 'message': Message(role='assistant', content='The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\\n\\n1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\\n2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\\n3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\\n4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\\n5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\\n6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\\n7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\\n8. **Diffusion Steps Reduction**: Reducing diffusion steps to improve speed while maintaining high output quality.\\n9. **Few-Shot Learning**: Restricting data and domain for few-shot learning to adapt to new environments with limited training data.\\n10. **Smooth Latent Space**: Investigating the latent space smoothness for diffusion models, which can be used to manipulate generated images and enable applications like image editing.\\n11. **Latent Space Disentanglement**: Exploring latent space disentanglement to separate factors of variation in the generated images.\\n12. **GAN-Inverse**: Using GAN-inverse methods to find the latent representation of a given image, enabling image editing and manipulation.\\n13. **Image Interpolation**: Using the latent space to interpolate between different images, creating new images that combine features from multiple sources.\\n14. **Image Inversion**: Using the latent space to invert the generation process, allowing for the reconstruction of the original input image.\\n15. **Quality Boosting**: Using the latent space to improve the quality of generated images, by manipulating the latent variables to produce more realistic and detailed images.\\n\\nThese methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.', images=None, tool_calls=None)} id='run-ed012b66-dc79-44f1-8c39-744862227d09' usage_metadata={'input_tokens': 8250, 'output_tokens': 516, 'total_tokens': 8766}\n",
      "The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "8. **Diffusion Steps Reduction**: Reducing diffusion steps to improve speed while maintaining high output quality.\n",
      "9. **Few-Shot Learning**: Restricting data and domain for few-shot learning to adapt to new environments with limited training data.\n",
      "10. **Smooth Latent Space**: Investigating the latent space smoothness for diffusion models, which can be used to manipulate generated images and enable applications like image editing.\n",
      "11. **Latent Space Disentanglement**: Exploring latent space disentanglement to separate factors of variation in the generated images.\n",
      "12. **GAN-Inverse**: Using GAN-inverse methods to find the latent representation of a given image, enabling image editing and manipulation.\n",
      "13. **Image Interpolation**: Using the latent space to interpolate between different images, creating new images that combine features from multiple sources.\n",
      "14. **Image Inversion**: Using the latent space to invert the generation process, allowing for the reconstruction of the original input image.\n",
      "15. **Quality Boosting**: Using the latent space to improve the quality of generated images, by manipulating the latent variables to produce more realistic and detailed images.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.\n",
      "\n",
      "\n",
      "metadata: \n",
      "{'thread_id': '2', 'langgraph_step': 18, 'langgraph_node': 'llm', 'langgraph_triggers': ['action'], 'langgraph_path': ('__pregel_pull', 'llm'), 'langgraph_checkpoint_ns': 'llm:0800f8e8-24c3-b430-ab6b-35065db131a3', 'checkpoint_ns': 'llm:0800f8e8-24c3-b430-ab6b-35065db131a3', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.3', 'ls_model_type': 'chat', 'ls_temperature': 0.5}\n",
      "\n",
      "\n",
      "The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "8. **Diffusion Steps Reduction**: Reducing diffusion steps to improve speed while maintaining high output quality.\n",
      "9. **Few-Shot Learning**: Restricting data and domain for few-shot learning to adapt to new environments with limited training data.\n",
      "10. **Smooth Latent Space**: Investigating the latent space smoothness for diffusion models, which can be used to manipulate generated images and enable applications like image editing.\n",
      "11. **Latent Space Disentanglement**: Exploring latent space disentanglement to separate factors of variation in the generated images.\n",
      "12. **GAN-Inverse**: Using GAN-inverse methods to find the latent representation of a given image, enabling image editing and manipulation.\n",
      "13. **Image Interpolation**: Using the latent space to interpolate between different images, creating new images that combine features from multiple sources.\n",
      "14. **Image Inversion**: Using the latent space to invert the generation process, allowing for the reconstruction of the original input image.\n",
      "15. **Quality Boosting**: Using the latent space to improve the quality of generated images, by manipulating the latent variables to produce more realistic and detailed images.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "8. **Diffusion Steps Reduction**: Reducing diffusion steps to improve speed while maintaining high output quality.\n",
      "9. **Few-Shot Learning**: Restricting data and domain for few-shot learning to adapt to new environments with limited training data.\n",
      "10. **Smooth Latent Space**: Investigating the latent space smoothness for diffusion models, which can be used to manipulate generated images and enable applications like image editing.\n",
      "11. **Latent Space Disentanglement**: Exploring latent space disentanglement to separate factors of variation in the generated images.\n",
      "12. **GAN-Inverse**: Using GAN-inverse methods to find the latent representation of a given image, enabling image editing and manipulation.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "8. **Diffusion Steps Reduction**: Reducing diffusion steps to improve speed while maintaining high output quality.\n",
      "9. **Few-Shot Learning**: Restricting data and domain for few-shot learning to adapt to new environments with limited training data.\n",
      "10. **Smooth Latent Space**: Investigating the latent space smoothness for diffusion models, which can be used to manipulate generated images and enable applications like image editing.\n",
      "11. **Latent Space Disentanglement**: Exploring latent space disentanglement to separate factors of variation in the generated images.\n",
      "12. **GAN-Inverse**: Using GAN-inverse methods to find the latent representation of a given image, enabling image editing and manipulation.\n",
      "13. **Image Interpolation**: Using the latent space to interpolate between different images, creating new images that combine features from multiple sources.\n",
      "14. **Image Inversion**: Using the latent space to invert the generation process, allowing for the reconstruction of the original input image.\n",
      "15. **Quality Boosting**: Using the latent space to improve the quality of generated images, by manipulating the latent variables to produce more realistic and detailed images.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs."
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": '2'}}\n",
    "inputs = {'messages': [HumanMessage(content=\"Please give a thorough and comprehensive list of some of the ways that the structure of a latent space in a diffusion model can be leveraged to help control the generation process?\")]}\n",
    "\n",
    "async for chunk_msg, metadata in abot.graph.astream(inputs, thread, stream_mode=\"messages\"):\n",
    "    if metadata[\"langgraph_node\"] == \"chatbot\":\n",
    "        if chunk_msg.content:\n",
    "            print(chunk_msg.content, end=\"\", flush=True)\n",
    "    else:\n",
    "        print(chunk_msg.content)\n",
    "        print(f\"\\n\\nmetadata: \\n{metadata}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received chunk: content='' additional_kwargs={} response_metadata={} id='run-39202feb-7715-43e9-8e15-063fc726478d' tool_calls=[{'name': 'search_chunks', 'args': {'k': 10, 'question': 'latent space structure control in diffusion models'}, 'id': 'db0d3838-8c94-40cc-aaf8-501dce757c3b', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'search_chunks', 'args': '{\"k\": 10, \"question\": \"latent space structure control in diffusion models\"}', 'id': 'db0d3838-8c94-40cc-aaf8-501dce757c3b', 'index': None, 'type': 'tool_call_chunk'}]\n",
      "Calling: {'name': 'search_chunks', 'args': {'k': 10, 'question': 'latent space structure control in diffusion models'}, 'id': 'db0d3838-8c94-40cc-aaf8-501dce757c3b', 'type': 'tool_call'}\n",
      "Received chunk: content='The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\\n\\n1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\\n2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\\n3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\\n4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\\n5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\\n6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\\n7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\\n\\nThese methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.' additional_kwargs={} response_metadata={'model': 'llama3.3', 'created_at': '2025-02-26T05:59:42.770491684Z', 'done': True, 'done_reason': 'stop', 'total_duration': 20550987029, 'load_duration': 33554505, 'prompt_eval_count': 2574, 'prompt_eval_duration': 2099000000, 'eval_count': 290, 'eval_duration': 18394000000, 'message': Message(role='assistant', content='The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\\n\\n1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\\n2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\\n3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\\n4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\\n5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\\n6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\\n7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\\n\\nThese methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.', images=None, tool_calls=None)} id='run-cfcc8858-0b26-40bd-8a57-79f37dbc0d67' usage_metadata={'input_tokens': 2574, 'output_tokens': 290, 'total_tokens': 2864}\n",
      "The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.============================\u001b[1m Aimessagechunk Message \u001b[0m============================\n",
      "\n",
      "The structure of a latent space in a diffusion model can be leveraged to help control the generation process in several ways:\n",
      "\n",
      "1. **Semantic Latent Space**: Discovering a semantic latent space in pretrained diffusion models allows for versatile editing and quality boosting by quantifiable measures such as edit strength and quality deficiency.\n",
      "2. **Latent Space Editing**: Smoothness of the latent space can be used to manipulate generated images, enabling applications like image interpolation, inversion, and editing.\n",
      "3. **ControlNet**: Adding conditional control to a large pretrained diffusion model using ControlNet allows for text-to-image diffusion with controlled outputs.\n",
      "4. **Principal Components Analysis (PCA)**: Finding interpretable directions in the latent space using PCA can correspond to global and semantically meaningful editing directions like pose, gender, and age.\n",
      "5. **Localized Changes**: Discovering directions based on a single input image can lead to highly localized changes in generated images, such as raising eyebrows or opening/closing mouth and eyes.\n",
      "6. **Transferability**: Directions found with respect to a specific image can be transferred to different samples, enabling high-quality editing of face images.\n",
      "7. **Riemannian Geometry**: Analyzing the latent space from a geometrical perspective using Riemannian geometry can provide insights into the structure of the latent space and its potential use for image editing tasks.\n",
      "\n",
      "These methods enable controlling the generation process in diffusion models, allowing for more precise and meaningful outputs.\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": '2'}}\n",
    "messages = [HumanMessage(content=\"Please give a thorough and comprehensive list of some of the ways that the structure of a latent space in a diffusion model can be leveraged to help control the generation process?\")]\n",
    "\n",
    "async def run_agent():\n",
    "    buffer = \"\"\n",
    "    async for event in abot.graph.astream({\"messages\": messages, \"buffer\": \"\"}, thread, stream_mode=\"updates\"):\n",
    "        if 'buffer' in event:\n",
    "            new_content = event['buffer']\n",
    "            buffer += new_content\n",
    "            print(new_content, end='', flush=True)\n",
    "\n",
    "await run_agent()\n",
    "\n",
    "# To get the final state:\n",
    "final_state = abot.graph.get_state(thread)\n",
    "final_message = final_state.values['messages'][-1]\n",
    "final_message.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received chunk: content='' additional_kwargs={} response_metadata={} id='run-de0d1784-5bdc-4ee6-a77a-c7419e74f7f5' tool_calls=[{'name': 'search_chunks', 'args': {'k': 10, 'question': 'item number 2 discussion'}, 'id': '7f8ec375-ba23-456a-a231-07c9358100f4', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'search_chunks', 'args': '{\"k\": 10, \"question\": \"item number 2 discussion\"}', 'id': '7f8ec375-ba23-456a-a231-07c9358100f4', 'index': None, 'type': 'tool_call_chunk'}]\n",
      "Calling: {'name': 'search_chunks', 'args': {'k': 10, 'question': 'item number 2 discussion'}, 'id': '7f8ec375-ba23-456a-a231-07c9358100f4', 'type': 'tool_call'}\n",
      "Received chunk: content='Item number 2 refers to the concept of a \"Smooth Latent Space\" in diffusion models. This concept is related to the idea of investigating the latent space smoothness for diffusion models, which remains unexplored.\\n\\nIn the context of diffusion models, the latent space is the space where the input data is represented after passing through an encoder. The smoothness of this space refers to how well the model can generate new samples that are similar to the training data.\\n\\nOne way to achieve a smooth latent space is by using techniques such as classifier-free guidance, which considers the probability of the input data given the condition (p(xt|y)) along with the probability of the condition given the input data (p(y|xt)) during sampling. This can help to generate samples that are further away from the null condition (∅) and closer to the desired condition (y).\\n\\nHowever, this approach can also lead to a mean shift and variance shift in the noise sample, which can accumulate through all the diffusion denoising steps and result in over-saturated images with over-smoothed textures.\\n\\nTo address this issue, researchers have proposed various methods, such as using a principled design of the generative process for versatile editing and quality boosting, or introducing a new loss function that encourages the model to generate samples that are similar to the training data.\\n\\nOverall, the concept of a smooth latent space in diffusion models is an active area of research, and there are many open questions and challenges that need to be addressed. However, by investigating this concept, researchers can develop new methods and techniques for improving the quality and diversity of generated samples, which can have many applications in computer vision and image processing.\\n\\nSome of the benefits of a smooth latent space include:\\n\\n* Improved image quality: By generating samples that are similar to the training data, diffusion models can produce high-quality images that are comparable to those produced by state-of-the-art generative models.\\n* Increased diversity: A smooth latent space can enable the generation of diverse samples that cover a wide range of possibilities, which can be useful for applications such as image editing and manipulation.\\n* Better control: By understanding the structure of the latent space, researchers can develop new methods for controlling the generation process, such as using vector arithmetic or introducing new loss functions.\\n\\nHowever, there are also challenges associated with achieving a smooth latent space, such as:\\n\\n* Mean shift and variance shift: As mentioned earlier, classifier-free guidance can lead to a mean shift and variance shift in the noise sample, which can result in over-saturated images with over-smoothed textures.\\n* Mode collapse: Diffusion models can suffer from mode collapse, where the model generates limited variations of the same output, rather than exploring the full range of possibilities.\\n* Training instability: Training diffusion models can be unstable, and small changes to the hyperparameters or training procedure can result in large changes to the generated samples.\\n\\nOverall, achieving a smooth latent space in diffusion models is an active area of research, and there are many open questions and challenges that need to be addressed. However, by investigating this concept, researchers can develop new methods and techniques for improving the quality and diversity of generated samples, which can have many applications in computer vision and image processing.' additional_kwargs={} response_metadata={'model': 'llama3.3', 'created_at': '2025-02-26T05:58:23.416543726Z', 'done': True, 'done_reason': 'stop', 'total_duration': 43770643590, 'load_duration': 33827928, 'prompt_eval_count': 4010, 'prompt_eval_duration': 1399000000, 'eval_count': 651, 'eval_duration': 42274000000, 'message': Message(role='assistant', content='Item number 2 refers to the concept of a \"Smooth Latent Space\" in diffusion models. This concept is related to the idea of investigating the latent space smoothness for diffusion models, which remains unexplored.\\n\\nIn the context of diffusion models, the latent space is the space where the input data is represented after passing through an encoder. The smoothness of this space refers to how well the model can generate new samples that are similar to the training data.\\n\\nOne way to achieve a smooth latent space is by using techniques such as classifier-free guidance, which considers the probability of the input data given the condition (p(xt|y)) along with the probability of the condition given the input data (p(y|xt)) during sampling. This can help to generate samples that are further away from the null condition (∅) and closer to the desired condition (y).\\n\\nHowever, this approach can also lead to a mean shift and variance shift in the noise sample, which can accumulate through all the diffusion denoising steps and result in over-saturated images with over-smoothed textures.\\n\\nTo address this issue, researchers have proposed various methods, such as using a principled design of the generative process for versatile editing and quality boosting, or introducing a new loss function that encourages the model to generate samples that are similar to the training data.\\n\\nOverall, the concept of a smooth latent space in diffusion models is an active area of research, and there are many open questions and challenges that need to be addressed. However, by investigating this concept, researchers can develop new methods and techniques for improving the quality and diversity of generated samples, which can have many applications in computer vision and image processing.\\n\\nSome of the benefits of a smooth latent space include:\\n\\n* Improved image quality: By generating samples that are similar to the training data, diffusion models can produce high-quality images that are comparable to those produced by state-of-the-art generative models.\\n* Increased diversity: A smooth latent space can enable the generation of diverse samples that cover a wide range of possibilities, which can be useful for applications such as image editing and manipulation.\\n* Better control: By understanding the structure of the latent space, researchers can develop new methods for controlling the generation process, such as using vector arithmetic or introducing new loss functions.\\n\\nHowever, there are also challenges associated with achieving a smooth latent space, such as:\\n\\n* Mean shift and variance shift: As mentioned earlier, classifier-free guidance can lead to a mean shift and variance shift in the noise sample, which can result in over-saturated images with over-smoothed textures.\\n* Mode collapse: Diffusion models can suffer from mode collapse, where the model generates limited variations of the same output, rather than exploring the full range of possibilities.\\n* Training instability: Training diffusion models can be unstable, and small changes to the hyperparameters or training procedure can result in large changes to the generated samples.\\n\\nOverall, achieving a smooth latent space in diffusion models is an active area of research, and there are many open questions and challenges that need to be addressed. However, by investigating this concept, researchers can develop new methods and techniques for improving the quality and diversity of generated samples, which can have many applications in computer vision and image processing.', images=None, tool_calls=None)} id='run-8654dbca-4c86-45c1-a512-8ce1d76154e8' usage_metadata={'input_tokens': 4010, 'output_tokens': 651, 'total_tokens': 4661}\n",
      "============================\u001b[1m Aimessagechunk Message \u001b[0m============================\n",
      "\n",
      "Item number 2 refers to the concept of a \"Smooth Latent Space\" in diffusion models. This concept is related to the idea of investigating the latent space smoothness for diffusion models, which remains unexplored.\n",
      "\n",
      "In the context of diffusion models, the latent space is the space where the input data is represented after passing through an encoder. The smoothness of this space refers to how well the model can generate new samples that are similar to the training data.\n",
      "\n",
      "One way to achieve a smooth latent space is by using techniques such as classifier-free guidance, which considers the probability of the input data given the condition (p(xt|y)) along with the probability of the condition given the input data (p(y|xt)) during sampling. This can help to generate samples that are further away from the null condition (∅) and closer to the desired condition (y).\n",
      "\n",
      "However, this approach can also lead to a mean shift and variance shift in the noise sample, which can accumulate through all the diffusion denoising steps and result in over-saturated images with over-smoothed textures.\n",
      "\n",
      "To address this issue, researchers have proposed various methods, such as using a principled design of the generative process for versatile editing and quality boosting, or introducing a new loss function that encourages the model to generate samples that are similar to the training data.\n",
      "\n",
      "Overall, the concept of a smooth latent space in diffusion models is an active area of research, and there are many open questions and challenges that need to be addressed. However, by investigating this concept, researchers can develop new methods and techniques for improving the quality and diversity of generated samples, which can have many applications in computer vision and image processing.\n",
      "\n",
      "Some of the benefits of a smooth latent space include:\n",
      "\n",
      "* Improved image quality: By generating samples that are similar to the training data, diffusion models can produce high-quality images that are comparable to those produced by state-of-the-art generative models.\n",
      "* Increased diversity: A smooth latent space can enable the generation of diverse samples that cover a wide range of possibilities, which can be useful for applications such as image editing and manipulation.\n",
      "* Better control: By understanding the structure of the latent space, researchers can develop new methods for controlling the generation process, such as using vector arithmetic or introducing new loss functions.\n",
      "\n",
      "However, there are also challenges associated with achieving a smooth latent space, such as:\n",
      "\n",
      "* Mean shift and variance shift: As mentioned earlier, classifier-free guidance can lead to a mean shift and variance shift in the noise sample, which can result in over-saturated images with over-smoothed textures.\n",
      "* Mode collapse: Diffusion models can suffer from mode collapse, where the model generates limited variations of the same output, rather than exploring the full range of possibilities.\n",
      "* Training instability: Training diffusion models can be unstable, and small changes to the hyperparameters or training procedure can result in large changes to the generated samples.\n",
      "\n",
      "Overall, achieving a smooth latent space in diffusion models is an active area of research, and there are many open questions and challenges that need to be addressed. However, by investigating this concept, researchers can develop new methods and techniques for improving the quality and diversity of generated samples, which can have many applications in computer vision and image processing.\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": '2'}}\n",
    "messages = [HumanMessage(content=\"Can you discuss item number 2 in more depth?\")]\n",
    "await run_agent()\n",
    "\n",
    "final_state = abot.graph.get_state(thread)\n",
    "final_message = final_state.values['messages'][-1]\n",
    "final_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": '1'}}\n",
    "messages = [HumanMessage(content=\"Who wrote the paper titled: Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models\")]\n",
    "async for event in abot.graph.astream({\"messages\":messages,}, thread, stream_mode=\"updates\"):\n",
    "    pass\n",
    "abot.graph.get_state(thread).values['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": '1'}}\n",
    "messages = [HumanMessage(content=\"How would you summarize the paper in 4 sentences?\")]\n",
    "async for event in abot.graph.astream({\"messages\":messages,}, thread, stream_mode=\"updates\"):\n",
    "    pass\n",
    "abot.graph.get_state(thread).values['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
