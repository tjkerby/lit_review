{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class RateLimitExceededError(Exception):\n",
    "    \"\"\"Custom exception for rate limit errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "def exponential_backoff_retry(\n",
    "    func,\n",
    "    title,\n",
    "    max_retries=5,\n",
    "    base_delay=1,\n",
    "    max_delay=32\n",
    "):\n",
    "    \"\"\"\n",
    "    Retries a function with exponential backoff.\n",
    "\n",
    "    Args:\n",
    "        func: A callable that may raise an exception.\n",
    "        title: The title of the paper to search for.\n",
    "        max_retries: Maximum number of retries before giving up.\n",
    "        base_delay: Initial delay in seconds.\n",
    "        max_delay: Maximum delay in seconds.\n",
    "\n",
    "    Returns:\n",
    "        The result of the function if successful.\n",
    "\n",
    "    Raises:\n",
    "        The last exception raised if all retries fail.\n",
    "    \"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            return func(title)\n",
    "        except RateLimitExceededError as e:\n",
    "            if attempt == max_retries:\n",
    "                raise  # Re-raise the last exception\n",
    "            else:\n",
    "                delay = min(base_delay * 2**(attempt - 1), max_delay)\n",
    "                print(f\"Attempt {attempt} failed due to rate limit. Retrying in {delay:.2f} seconds...\")\n",
    "                time.sleep(delay)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            raise\n",
    "\n",
    "def search_paper_by_title(title):\n",
    "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "    params = {\n",
    "        \"query\": f\"title:({title})\",\n",
    "        \"fields\": \"title,url,publicationTypes,publicationDate,openAccessPdf,citationCount,authors,abstract\",\n",
    "        \"year\": \"2020-\",\n",
    "        \"limit\": 1  # Adjust as needed\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"data\"):\n",
    "            return data[\"data\"][0]  # Return the first matching paper\n",
    "        else:\n",
    "            print(f\"No matching papers found for {title}.\")\n",
    "            return None\n",
    "    elif response.status_code == 429:\n",
    "        raise RateLimitExceededError(\"Rate limit exceeded. Please wait before retrying.\")\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "        \n",
    "def get_paper_citations(paper_id, fields=None, year=None, limit=None):\n",
    "    \"\"\"\n",
    "    Retrieves citation information for a given paper ID from the Semantic Scholar API.\n",
    "\n",
    "    Args:\n",
    "        paper_id (str): The Semantic Scholar paper ID.\n",
    "        fields (list, optional): List of fields to include in the response. Defaults to None. Options include:\n",
    "            * title\n",
    "            * url\n",
    "            * publicationTypes\n",
    "            * publicationDate\n",
    "            * openAccessPdf\n",
    "            * citationCount\n",
    "            * authors\n",
    "            * abstract\n",
    "            * contexts\n",
    "            * intents\n",
    "            * isInfluential\n",
    "\n",
    "    Returns:\n",
    "        dict: Citation data for the specified paper.\n",
    "    \"\"\"\n",
    "    base_url = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/citations\"\n",
    "    params = {}\n",
    "    if fields:\n",
    "        params['fields'] = ','.join(fields)\n",
    "    if year:\n",
    "        params['year'] = year\n",
    "    if limit:\n",
    "        params['limit'] = limit\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: Unable to fetch citations for paper ID {paper_id}\")\n",
    "        return None\n",
    "    \n",
    "def get_paper_references(paper_id, fields=None, year=None, limit=None):\n",
    "    \"\"\"\n",
    "    Retrieves citation information for a given paper ID from the Semantic Scholar API.\n",
    "\n",
    "    Args:\n",
    "        paper_id (str): The Semantic Scholar paper ID.\n",
    "        fields (list, optional): List of fields to include in the response. Defaults to None. Options include:\n",
    "            * title\n",
    "            * url\n",
    "            * publicationTypes\n",
    "            * publicationDate\n",
    "            * openAccessPdf\n",
    "            * citationCount\n",
    "            * authors\n",
    "            * abstract\n",
    "            * contexts\n",
    "            * intents\n",
    "            * isInfluential\n",
    "\n",
    "    Returns:\n",
    "        dict: Citation data for the specified paper.\n",
    "    \"\"\"\n",
    "    base_url = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/references\"\n",
    "    params = {}\n",
    "    if fields:\n",
    "        params['fields'] = ','.join(fields)\n",
    "    if year:\n",
    "        params['year'] = year\n",
    "    if limit:\n",
    "        params['limit'] = limit\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: Unable to fetch citations for paper ID {paper_id}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching papers found for A Survey of Multimodal Controllable Diffusion Models.\n",
      "No matching papers found for Hierarchical Clustering for Conditional Diffusion in Image Generation.\n",
      "No matching papers found for Gradient Guidance for Diffusion Models: An Optimization Perspective.\n",
      "                                     paperId  \\\n",
      "0   ca743e75ce090bbf686307e41bd8747661768fbe   \n",
      "1   4f1502111d35aa6651dfaedfeb1184b3c3dd2fcb   \n",
      "2   3333fa6dc9d39cad3d5cd87da9ae39e5a6aefe27   \n",
      "3   36a5328c337697b96c9e6a9a04df0c924aa421f7   \n",
      "4   0bbd619ad6dfb69114735d6d8ca166c20301188b   \n",
      "5   2cfb086b6414e990a2203da746c05ba0c0638134   \n",
      "6   5a613652d700f9a271b6d01c7d9e4223e9883300   \n",
      "7   b798c925a4c43ea09e76a1c748491ef70067c0c6   \n",
      "8   019abc8974dd46d7eec9a51818f64cc896c66499   \n",
      "9   efbe97d20c4ffe356e8826c01dc550bacc405add   \n",
      "10  a02313d56a6f71be9aafe43628e0f3a1d0cb858e   \n",
      "11  d7074976c2609568902a6b6ca45f6c71d9cb66bf   \n",
      "12  36a5328c337697b96c9e6a9a04df0c924aa421f7   \n",
      "13  c27da349811cbbafd5896befb0bb138d87583873   \n",
      "14  d9822d11ae4ead1f1d32c43124a6a0eb80ea4f0c   \n",
      "\n",
      "                                                  url  \\\n",
      "0   https://www.semanticscholar.org/paper/ca743e75...   \n",
      "1   https://www.semanticscholar.org/paper/4f150211...   \n",
      "2   https://www.semanticscholar.org/paper/3333fa6d...   \n",
      "3   https://www.semanticscholar.org/paper/36a5328c...   \n",
      "4   https://www.semanticscholar.org/paper/0bbd619a...   \n",
      "5   https://www.semanticscholar.org/paper/2cfb086b...   \n",
      "6   https://www.semanticscholar.org/paper/5a613652...   \n",
      "7   https://www.semanticscholar.org/paper/b798c925...   \n",
      "8   https://www.semanticscholar.org/paper/019abc89...   \n",
      "9   https://www.semanticscholar.org/paper/efbe97d2...   \n",
      "10  https://www.semanticscholar.org/paper/a02313d5...   \n",
      "11  https://www.semanticscholar.org/paper/d7074976...   \n",
      "12  https://www.semanticscholar.org/paper/36a5328c...   \n",
      "13  https://www.semanticscholar.org/paper/c27da349...   \n",
      "14  https://www.semanticscholar.org/paper/d9822d11...   \n",
      "\n",
      "                                                title  \\\n",
      "0   Latent Space Editing in Transformer-Based Flow...   \n",
      "1   Paint by Example: Exemplar-based Image Editing...   \n",
      "2   Smooth Diffusion: Crafting Smooth Latent Space...   \n",
      "3   Unifying Diffusion Models' Latent Space, with ...   \n",
      "4   Learned Representation-Guided Diffusion Models...   \n",
      "5   GDUI: Guided Diffusion Model for Unlabeled Images   \n",
      "6   Nested Diffusion Models Using Hierarchical Lat...   \n",
      "7                        Self-Guided Diffusion Models   \n",
      "8   DiffMat: Latent diffusion models for image-gui...   \n",
      "9   Adding Conditional Control to Text-to-Image Di...   \n",
      "10  Diffusion Models already have a Semantic Laten...   \n",
      "11  Understanding the Latent Space of Diffusion Mo...   \n",
      "12  Unifying Diffusion Models' Latent Space, with ...   \n",
      "13  Motion Guidance: Diffusion-Based Image Editing...   \n",
      "14  Seeing and Hearing: Open-domain Visual-Audio G...   \n",
      "\n",
      "                                             abstract  citationCount  \\\n",
      "0   This paper strives for image editing via gener...             22   \n",
      "1   Language-guided image editing has achieved gre...            327   \n",
      "2   Recently, diffusion models have made remarkabl...             15   \n",
      "3   Diffusion models have achieved unprecedented p...             59   \n",
      "4   To synthesize high-fidelity samples, diffusion...             15   \n",
      "5   The diffusion model has made progress in the f...              0   \n",
      "6   We introduce nested diffusion models, an effic...              0   \n",
      "7   Diffusion models have demonstrated remarkable ...             26   \n",
      "8                                                None              8   \n",
      "9   We present ControlNet, a neural network archit...           2934   \n",
      "10  Diffusion models achieve outstanding generativ...            201   \n",
      "11  Despite the success of diffusion models (DMs),...             34   \n",
      "12  Diffusion models have achieved unprecedented p...             59   \n",
      "13  Diffusion models are capable of generating imp...             18   \n",
      "14  Video and audio content creation serves as the...             32   \n",
      "\n",
      "    openAccessPdf              publicationTypes publicationDate  \\\n",
      "0             NaN  [JournalArticle, Conference]      2023-12-17   \n",
      "1             NaN  [JournalArticle, Conference]      2022-11-23   \n",
      "2             NaN  [JournalArticle, Conference]      2023-12-07   \n",
      "3             NaN              [JournalArticle]      2022-10-11   \n",
      "4             NaN  [JournalArticle, Conference]      2023-12-12   \n",
      "5             NaN              [JournalArticle]      2024-03-18   \n",
      "6             NaN                          None      2024-12-08   \n",
      "7             NaN  [JournalArticle, Conference]      2022-10-12   \n",
      "8             NaN              [JournalArticle]      2024-01-01   \n",
      "9             NaN  [JournalArticle, Conference]      2023-02-10   \n",
      "10            NaN              [JournalArticle]      2022-10-20   \n",
      "11            NaN              [JournalArticle]      2023-07-24   \n",
      "12            NaN              [JournalArticle]      2022-10-11   \n",
      "13            NaN              [JournalArticle]      2024-01-31   \n",
      "14            NaN  [JournalArticle, Conference]      2024-02-27   \n",
      "\n",
      "                                              authors  \\\n",
      "0   [{'authorId': '2066967977', 'name': 'Vincent T...   \n",
      "1   [{'authorId': '2157857267', 'name': 'Binxin Ya...   \n",
      "2   [{'authorId': '2148900054', 'name': 'Jiayi Guo...   \n",
      "3   [{'authorId': '114621402', 'name': 'Chen Henry...   \n",
      "4   [{'authorId': '1816769252', 'name': 'Alexandro...   \n",
      "5   [{'authorId': '2292216595', 'name': 'Xuanyuan ...   \n",
      "6   [{'authorId': '2257050718', 'name': 'Xiao Zhan...   \n",
      "7   [{'authorId': '2066967977', 'name': 'Vincent T...   \n",
      "8   [{'authorId': '2277656779', 'name': 'Liang Yua...   \n",
      "9   [{'authorId': '17744884', 'name': 'Lvmin Zhang...   \n",
      "10  [{'authorId': '2182293854', 'name': 'Mingi Kwo...   \n",
      "11  [{'authorId': '2209948157', 'name': 'Yong-Hyun...   \n",
      "12  [{'authorId': '114621402', 'name': 'Chen Henry...   \n",
      "13  [{'authorId': '2268490283', 'name': 'Daniel Ge...   \n",
      "14  [{'authorId': '2072727444', 'name': 'Yazhou Xi...   \n",
      "\n",
      "                                    openAccessPdf.url openAccessPdf.status  \n",
      "0                                                 NaN                  NaN  \n",
      "1                    https://arxiv.org/pdf/2211.13227                GREEN  \n",
      "2                    https://arxiv.org/pdf/2312.04410                GREEN  \n",
      "3                    https://arxiv.org/pdf/2210.05559                GREEN  \n",
      "4                    https://arxiv.org/pdf/2312.07330                GREEN  \n",
      "5   https://www.mdpi.com/1999-4893/17/3/125/pdf?ve...                 GOLD  \n",
      "6                                                 NaN                  NaN  \n",
      "7                    https://arxiv.org/pdf/2210.06462                GREEN  \n",
      "8                                                 NaN                  NaN  \n",
      "9                    https://arxiv.org/pdf/2302.05543                GREEN  \n",
      "10                    http://arxiv.org/pdf/2210.10960                GREEN  \n",
      "11                   https://arxiv.org/pdf/2307.12868                GREEN  \n",
      "12                   https://arxiv.org/pdf/2210.05559                GREEN  \n",
      "13                                                NaN                  NaN  \n",
      "14                    http://arxiv.org/pdf/2402.17723                GREEN  \n"
     ]
    }
   ],
   "source": [
    "paper_titles = [\n",
    "    'Latent Space Editing in Transformer-Based Flow Matching', \n",
    "    'A Survey of Multimodal Controllable Diffusion Models',\n",
    "    'Paint by Example: Exemplar-based Image Editing with Diffusion Models',\n",
    "    'Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models',\n",
    "    \"Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance\",\n",
    "    'Learned representation-guided diffusion models for large-image generation',\n",
    "    'GDUI: Guided Diffusion Model for Unlabeled Images',\n",
    "    \"Hierarchical Clustering for Conditional Diffusion in Image Generation\",\n",
    "    \"Nested Diffusion Models Using Hierarchical Latent Priors\",\n",
    "    \"Self-Guided Diffusion Models\",\n",
    "    \"Gradient Guidance for Diffusion Models: An Optimization Perspective\",\n",
    "    \"DiffMat: Latent diffusion models for image-guided material generation\",\n",
    "    \"Adding Conditional Control to Text-to-Image Diffusion Models\",\n",
    "    \"DIFFUSION MODELS ALREADY HAVE A SEMANTIC LATENT SPACE\",\n",
    "    \"Understanding the Latent Space of Diffusion Models through the Lens of Riemannian Geometry\",\n",
    "    \"UNIFYING DIFFUSION MODELS' LATENT SPACE, WITH APPLICATIONS TO CYCLEDIFFUSION AND GUIDANCE\",\n",
    "    \"MOTION GUIDANCE: DIFFUSION-BASED IMAGE EDITING WITH DIFFERENTIABLE MOTION ESTIMATORS\",\n",
    "    \"Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners\"\n",
    "]\n",
    "\n",
    "data = []\n",
    "for title in paper_titles:\n",
    "    try:\n",
    "        paper_data = exponential_backoff_retry(search_paper_by_title, title)\n",
    "        if paper_data:\n",
    "            # print(json.dumps(paper_data, indent=2))\n",
    "            data.append(paper_data)\n",
    "    except RateLimitExceededError:\n",
    "        print(\"Exceeded rate limit. Please try again later.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(data):\n",
    "    print(f\"{paper_titles[i]}:\\n{data[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paperId', 'url', 'title', 'abstract', 'citationCount', 'openAccessPdf',\n",
       "       'publicationTypes', 'publicationDate', 'authors', 'openAccessPdf.url',\n",
       "       'openAccessPdf.status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>publicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Latent Space Editing in Transformer-Based Flow...</td>\n",
       "      <td>22</td>\n",
       "      <td>2023-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paint by Example: Exemplar-based Image Editing...</td>\n",
       "      <td>327</td>\n",
       "      <td>2022-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smooth Diffusion: Crafting Smooth Latent Space...</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unifying Diffusion Models' Latent Space, with ...</td>\n",
       "      <td>59</td>\n",
       "      <td>2022-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learned Representation-Guided Diffusion Models...</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GDUI: Guided Diffusion Model for Unlabeled Images</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nested Diffusion Models Using Hierarchical Lat...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Self-Guided Diffusion Models</td>\n",
       "      <td>26</td>\n",
       "      <td>2022-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DiffMat: Latent diffusion models for image-gui...</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adding Conditional Control to Text-to-Image Di...</td>\n",
       "      <td>2934</td>\n",
       "      <td>2023-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Diffusion Models already have a Semantic Laten...</td>\n",
       "      <td>201</td>\n",
       "      <td>2022-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Understanding the Latent Space of Diffusion Mo...</td>\n",
       "      <td>34</td>\n",
       "      <td>2023-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unifying Diffusion Models' Latent Space, with ...</td>\n",
       "      <td>59</td>\n",
       "      <td>2022-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Motion Guidance: Diffusion-Based Image Editing...</td>\n",
       "      <td>18</td>\n",
       "      <td>2024-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Seeing and Hearing: Open-domain Visual-Audio G...</td>\n",
       "      <td>32</td>\n",
       "      <td>2024-02-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  citationCount  \\\n",
       "0   Latent Space Editing in Transformer-Based Flow...             22   \n",
       "1   Paint by Example: Exemplar-based Image Editing...            327   \n",
       "2   Smooth Diffusion: Crafting Smooth Latent Space...             15   \n",
       "3   Unifying Diffusion Models' Latent Space, with ...             59   \n",
       "4   Learned Representation-Guided Diffusion Models...             15   \n",
       "5   GDUI: Guided Diffusion Model for Unlabeled Images              0   \n",
       "6   Nested Diffusion Models Using Hierarchical Lat...              0   \n",
       "7                        Self-Guided Diffusion Models             26   \n",
       "8   DiffMat: Latent diffusion models for image-gui...              8   \n",
       "9   Adding Conditional Control to Text-to-Image Di...           2934   \n",
       "10  Diffusion Models already have a Semantic Laten...            201   \n",
       "11  Understanding the Latent Space of Diffusion Mo...             34   \n",
       "12  Unifying Diffusion Models' Latent Space, with ...             59   \n",
       "13  Motion Guidance: Diffusion-Based Image Editing...             18   \n",
       "14  Seeing and Hearing: Open-domain Visual-Audio G...             32   \n",
       "\n",
       "   publicationDate  \n",
       "0       2023-12-17  \n",
       "1       2022-11-23  \n",
       "2       2023-12-07  \n",
       "3       2022-10-11  \n",
       "4       2023-12-12  \n",
       "5       2024-03-18  \n",
       "6       2024-12-08  \n",
       "7       2022-10-12  \n",
       "8       2024-01-01  \n",
       "9       2023-02-10  \n",
       "10      2022-10-20  \n",
       "11      2023-07-24  \n",
       "12      2022-10-11  \n",
       "13      2024-01-31  \n",
       "14      2024-02-27  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title', 'citationCount', 'publicationDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citedPaper.paperId</th>\n",
       "      <th>citedPaper.title</th>\n",
       "      <th>citedPaper.abstract</th>\n",
       "      <th>citedPaper.citationCount</th>\n",
       "      <th>citedPaper.publicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c231418d40fa0eb67ee6a1901add09e9af433a4f</td>\n",
       "      <td>Guided Diffusion from Self-Supervised Diffusio...</td>\n",
       "      <td>Guidance serves as a key concept in diffusion ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f403d194b42d10c3a438736388c8812831b1361</td>\n",
       "      <td>Latent Traversals in Generative Models as Pote...</td>\n",
       "      <td>Despite the significant recent progress in dee...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2023-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>721f9afcfe45c70ba0a98f8aed833e28b278b275</td>\n",
       "      <td>DiffFit: Unlocking Transferability of Large Di...</td>\n",
       "      <td>Diffusion models have proven to be highly effe...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2023-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1c33172c2ffbc038f0598f3ac56bb04af79c904</td>\n",
       "      <td>An Edit Friendly DDPM Noise Space: Inversion a...</td>\n",
       "      <td>Denoising diffusion probabilistic models (DDPM...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2023-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d9b95937934d7291b7c253b28b6c9aaee033c91d</td>\n",
       "      <td>Forget-Me-Not: Learning to Forget in Text-to-I...</td>\n",
       "      <td>The significant advances in applications of te...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2023-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a64e9fe44051d93202853a43656def4b44f84883</td>\n",
       "      <td>Discovering Interpretable Directions in the Se...</td>\n",
       "      <td>Denoising Diffusion Models (DDMs) have emerged...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2023-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6d23c64e7feb217d53f01f532e8e8885e62f76b2</td>\n",
       "      <td>Unsupervised Discovery of Semantic Latent Dire...</td>\n",
       "      <td>Despite the success of diffusion models (DMs),...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2023-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d24b4f34197df0257390b57f02537e6ce3284f2e</td>\n",
       "      <td>Universal Guidance for Diffusion Models</td>\n",
       "      <td>Typical diffusion models are trained to accept...</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2023-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>be6d7185c4579d911e9ad059b3834395d43d7f28</td>\n",
       "      <td>Minimizing Trajectory Curvature of ODE-based G...</td>\n",
       "      <td>Recent ODE/SDE-based generative models, such a...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2023-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7acc71fad70c4c65203739f156bcb440587df901</td>\n",
       "      <td>Scalable Adaptive Computation for Iterative Ge...</td>\n",
       "      <td>Natural data is redundant yet predominant arch...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2022-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>736973165f98105fec3729b7db414ae4d80fcbeb</td>\n",
       "      <td>Scalable Diffusion Models with Transformers</td>\n",
       "      <td>We explore a new class of diffusion models bas...</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>2022-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>524889248251669b110adf86c4380444ec5448f4</td>\n",
       "      <td>Fast Point Cloud Generation with Straight Flows</td>\n",
       "      <td>Diffusion models have emerged as a powerful to...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2022-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a02313d56a6f71be9aafe43628e0f3a1d0cb858e</td>\n",
       "      <td>Diffusion Models already have a Semantic Laten...</td>\n",
       "      <td>Diffusion models achieve outstanding generativ...</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2022-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b798c925a4c43ea09e76a1c748491ef70067c0c6</td>\n",
       "      <td>Self-Guided Diffusion Models</td>\n",
       "      <td>Diffusion models have demonstrated remarkable ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2022-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>af68f10ab5078bfc519caae377c90ee6d9c504e9</td>\n",
       "      <td>Flow Matching for Generative Modeling</td>\n",
       "      <td>We introduce a new paradigm for generative mod...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2022-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>244054a4254a2147e43a3dad9c124b9b7eb4a04a</td>\n",
       "      <td>Flow Straight and Fast: Learning to Generate a...</td>\n",
       "      <td>We present rectified flow, a surprisingly simp...</td>\n",
       "      <td>487.0</td>\n",
       "      <td>2022-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a815b0a955db2163617baf308020c3d770da099d</td>\n",
       "      <td>Your ViT is Secretly a Hybrid Discriminative-G...</td>\n",
       "      <td>Diffusion Denoising Probability Models (DDPM) ...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2022-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>04e541391e8dce14d099d00fb2c21dbbd8afe87f</td>\n",
       "      <td>Prompt-to-Prompt Image Editing with Cross Atte...</td>\n",
       "      <td>Recent large-scale text-driven synthesis model...</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>2022-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9695824d7a01fad57ba9c01d7d76a519d78d65e7</td>\n",
       "      <td>Photorealistic Text-to-Image Diffusion Models ...</td>\n",
       "      <td>We present Imagen, a text-to-image diffusion m...</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>2022-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c57293882b2561e1ba03017902df9fc2f289dea2</td>\n",
       "      <td>Hierarchical Text-Conditional Image Generation...</td>\n",
       "      <td>Contrastive models like CLIP have been shown t...</td>\n",
       "      <td>5757.0</td>\n",
       "      <td>2022-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c10075b3746a9f3dd5811970e93c8ca3ad39b39d</td>\n",
       "      <td>High-Resolution Image Synthesis with Latent Di...</td>\n",
       "      <td>By decomposing the image formation process int...</td>\n",
       "      <td>11760.0</td>\n",
       "      <td>2021-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8f8dedb511c0324d1cb7f9750560109ca9290b5f</td>\n",
       "      <td>DiffusionCLIP: Text-Guided Diffusion Models fo...</td>\n",
       "      <td>Recently, GAN inversion methods combined with ...</td>\n",
       "      <td>537.0</td>\n",
       "      <td>2021-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>f671a09e3e5922e6d38cb77dda8d76d5ceac2a27</td>\n",
       "      <td>SDEdit: Guided Image Synthesis and Editing wit...</td>\n",
       "      <td>Guided image synthesis enables everyday users ...</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>2021-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b13cbe9f3dca05eead110d59ce51087f3b7e1d24</td>\n",
       "      <td>TediGAN: Text-Guided Diverse Face Image Genera...</td>\n",
       "      <td>In this work, we propose TediGAN, a novel fram...</td>\n",
       "      <td>325.0</td>\n",
       "      <td>2021-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2cd605106b88c85d7d8b865b1ef0f8c8293debf1</td>\n",
       "      <td>Zero-Shot Text-to-Image Generation</td>\n",
       "      <td>Text-to-image generation has traditionally foc...</td>\n",
       "      <td>4191.0</td>\n",
       "      <td>2021-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>268d347e8a55b5eb82fb5e7d2f800e33c75ab18a</td>\n",
       "      <td>An Image is Worth 16x16 Words: Transformers fo...</td>\n",
       "      <td>While the Transformer architecture has become ...</td>\n",
       "      <td>32312.0</td>\n",
       "      <td>2020-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dc0668754e95da573cd64dbe5e2fed07ac9ddf97</td>\n",
       "      <td>InterFaceGAN: Interpreting the Disentangled Fa...</td>\n",
       "      <td>Although generative adversarial networks (GANs...</td>\n",
       "      <td>555.0</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>d8d89a0a1eca983512247af701a9e5596c903a16</td>\n",
       "      <td>Interpreting the Latent Space of GANs for Sema...</td>\n",
       "      <td>Despite the recent advance of Generative Adver...</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2019-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>df7ad8eeb595da5f7774e91dae06075be952acff</td>\n",
       "      <td>GAN Dissection: Visualizing and Understanding ...</td>\n",
       "      <td>Generative Adversarial Networks (GANs) have re...</td>\n",
       "      <td>445.0</td>\n",
       "      <td>2018-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>449310e3538b08b43227d660227dfd2875c3c3c1</td>\n",
       "      <td>Neural Ordinary Differential Equations</td>\n",
       "      <td>We introduce a new family of deep neural netwo...</td>\n",
       "      <td>4452.0</td>\n",
       "      <td>2018-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>c468bbde6a22d961829e1970e6ad5795e05418d1</td>\n",
       "      <td>The Unreasonable Effectiveness of Deep Feature...</td>\n",
       "      <td>While it is nearly effortless for humans to qu...</td>\n",
       "      <td>9772.0</td>\n",
       "      <td>2018-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6364fdaa0a0eccd823a779fcdd489173f938e91a</td>\n",
       "      <td>U-Net: Convolutional Networks for Biomedical I...</td>\n",
       "      <td>None</td>\n",
       "      <td>69797.0</td>\n",
       "      <td>2015-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>71b7178df5d2b112d07e45038cb5637208659ff7</td>\n",
       "      <td>Microsoft COCO: Common Objects in Context</td>\n",
       "      <td>None</td>\n",
       "      <td>39938.0</td>\n",
       "      <td>2014-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>df1c1cb4a547b9b207613d81765d4693dde9590b</td>\n",
       "      <td>A family of embedded Runge-Kutta formulae</td>\n",
       "      <td>None</td>\n",
       "      <td>3290.0</td>\n",
       "      <td>1980-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>90428f3a8caa5082f825ebf3138514ddf273dae3</td>\n",
       "      <td>Supplementary Materials for: NULL-text Inversi...</td>\n",
       "      <td>Most of the presented results consist of apply...</td>\n",
       "      <td>657.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ae165a3c5d31f7024e017b3902d97ac9959de2b8</td>\n",
       "      <td>Training-free Style Transfer Emerges from h-sp...</td>\n",
       "      <td>Diffusion models (DMs) synthesize high-quality...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16571a7eebed728345f7f4ce8f260662c0b439f2</td>\n",
       "      <td>All are Worth Words: a ViT Backbone for Score-...</td>\n",
       "      <td>Vision transformers (ViT) have shown promise i...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>f658c519e521d9f524bf1343e4d8e64c8af7f9ce</td>\n",
       "      <td>Randomized Conditional Flow Matching for Video...</td>\n",
       "      <td>We introduce a novel generative model for vide...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0eacb09ebe35460e4ac83bf846d1f1dc8e24a33b</td>\n",
       "      <td>Action Matching: A Variational Method for Lear...</td>\n",
       "      <td>,</td>\n",
       "      <td>24.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ef4f5a50837a7c1b3e87b9300ffc7ba00d461a0f</td>\n",
       "      <td>AUTO-ENCODING VARIATIONAL BAYES</td>\n",
       "      <td>To make decisions based on a model fit by Auto...</td>\n",
       "      <td>13595.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>47f8a708cce5d1ea1482d3dc35f0aabc1fa90a65</td>\n",
       "      <td>Beitrag zur Naherungsweisen Integration Totale...</td>\n",
       "      <td>None</td>\n",
       "      <td>493.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>None</td>\n",
       "      <td>¨Uber die numerische Aufl¨osung von Dif-ferent...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>None</td>\n",
       "      <td>2023. Riemannian flow matching on general geom...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          citedPaper.paperId  \\\n",
       "0   c231418d40fa0eb67ee6a1901add09e9af433a4f   \n",
       "1   2f403d194b42d10c3a438736388c8812831b1361   \n",
       "2   721f9afcfe45c70ba0a98f8aed833e28b278b275   \n",
       "3   d1c33172c2ffbc038f0598f3ac56bb04af79c904   \n",
       "4   d9b95937934d7291b7c253b28b6c9aaee033c91d   \n",
       "5   a64e9fe44051d93202853a43656def4b44f84883   \n",
       "6   6d23c64e7feb217d53f01f532e8e8885e62f76b2   \n",
       "7   d24b4f34197df0257390b57f02537e6ce3284f2e   \n",
       "8   be6d7185c4579d911e9ad059b3834395d43d7f28   \n",
       "9   7acc71fad70c4c65203739f156bcb440587df901   \n",
       "10  736973165f98105fec3729b7db414ae4d80fcbeb   \n",
       "11  524889248251669b110adf86c4380444ec5448f4   \n",
       "12  a02313d56a6f71be9aafe43628e0f3a1d0cb858e   \n",
       "13  b798c925a4c43ea09e76a1c748491ef70067c0c6   \n",
       "14  af68f10ab5078bfc519caae377c90ee6d9c504e9   \n",
       "15  244054a4254a2147e43a3dad9c124b9b7eb4a04a   \n",
       "16  a815b0a955db2163617baf308020c3d770da099d   \n",
       "17  04e541391e8dce14d099d00fb2c21dbbd8afe87f   \n",
       "18  9695824d7a01fad57ba9c01d7d76a519d78d65e7   \n",
       "19  c57293882b2561e1ba03017902df9fc2f289dea2   \n",
       "20  c10075b3746a9f3dd5811970e93c8ca3ad39b39d   \n",
       "21  8f8dedb511c0324d1cb7f9750560109ca9290b5f   \n",
       "22  f671a09e3e5922e6d38cb77dda8d76d5ceac2a27   \n",
       "23  b13cbe9f3dca05eead110d59ce51087f3b7e1d24   \n",
       "24  2cd605106b88c85d7d8b865b1ef0f8c8293debf1   \n",
       "25  268d347e8a55b5eb82fb5e7d2f800e33c75ab18a   \n",
       "26  dc0668754e95da573cd64dbe5e2fed07ac9ddf97   \n",
       "27  d8d89a0a1eca983512247af701a9e5596c903a16   \n",
       "28  df7ad8eeb595da5f7774e91dae06075be952acff   \n",
       "29  449310e3538b08b43227d660227dfd2875c3c3c1   \n",
       "30  c468bbde6a22d961829e1970e6ad5795e05418d1   \n",
       "31  6364fdaa0a0eccd823a779fcdd489173f938e91a   \n",
       "32  71b7178df5d2b112d07e45038cb5637208659ff7   \n",
       "33  df1c1cb4a547b9b207613d81765d4693dde9590b   \n",
       "34  90428f3a8caa5082f825ebf3138514ddf273dae3   \n",
       "35  ae165a3c5d31f7024e017b3902d97ac9959de2b8   \n",
       "36  16571a7eebed728345f7f4ce8f260662c0b439f2   \n",
       "37  f658c519e521d9f524bf1343e4d8e64c8af7f9ce   \n",
       "38  0eacb09ebe35460e4ac83bf846d1f1dc8e24a33b   \n",
       "39  ef4f5a50837a7c1b3e87b9300ffc7ba00d461a0f   \n",
       "40  47f8a708cce5d1ea1482d3dc35f0aabc1fa90a65   \n",
       "41                                      None   \n",
       "42                                      None   \n",
       "\n",
       "                                     citedPaper.title  \\\n",
       "0   Guided Diffusion from Self-Supervised Diffusio...   \n",
       "1   Latent Traversals in Generative Models as Pote...   \n",
       "2   DiffFit: Unlocking Transferability of Large Di...   \n",
       "3   An Edit Friendly DDPM Noise Space: Inversion a...   \n",
       "4   Forget-Me-Not: Learning to Forget in Text-to-I...   \n",
       "5   Discovering Interpretable Directions in the Se...   \n",
       "6   Unsupervised Discovery of Semantic Latent Dire...   \n",
       "7             Universal Guidance for Diffusion Models   \n",
       "8   Minimizing Trajectory Curvature of ODE-based G...   \n",
       "9   Scalable Adaptive Computation for Iterative Ge...   \n",
       "10        Scalable Diffusion Models with Transformers   \n",
       "11    Fast Point Cloud Generation with Straight Flows   \n",
       "12  Diffusion Models already have a Semantic Laten...   \n",
       "13                       Self-Guided Diffusion Models   \n",
       "14              Flow Matching for Generative Modeling   \n",
       "15  Flow Straight and Fast: Learning to Generate a...   \n",
       "16  Your ViT is Secretly a Hybrid Discriminative-G...   \n",
       "17  Prompt-to-Prompt Image Editing with Cross Atte...   \n",
       "18  Photorealistic Text-to-Image Diffusion Models ...   \n",
       "19  Hierarchical Text-Conditional Image Generation...   \n",
       "20  High-Resolution Image Synthesis with Latent Di...   \n",
       "21  DiffusionCLIP: Text-Guided Diffusion Models fo...   \n",
       "22  SDEdit: Guided Image Synthesis and Editing wit...   \n",
       "23  TediGAN: Text-Guided Diverse Face Image Genera...   \n",
       "24                 Zero-Shot Text-to-Image Generation   \n",
       "25  An Image is Worth 16x16 Words: Transformers fo...   \n",
       "26  InterFaceGAN: Interpreting the Disentangled Fa...   \n",
       "27  Interpreting the Latent Space of GANs for Sema...   \n",
       "28  GAN Dissection: Visualizing and Understanding ...   \n",
       "29             Neural Ordinary Differential Equations   \n",
       "30  The Unreasonable Effectiveness of Deep Feature...   \n",
       "31  U-Net: Convolutional Networks for Biomedical I...   \n",
       "32          Microsoft COCO: Common Objects in Context   \n",
       "33          A family of embedded Runge-Kutta formulae   \n",
       "34  Supplementary Materials for: NULL-text Inversi...   \n",
       "35  Training-free Style Transfer Emerges from h-sp...   \n",
       "36  All are Worth Words: a ViT Backbone for Score-...   \n",
       "37  Randomized Conditional Flow Matching for Video...   \n",
       "38  Action Matching: A Variational Method for Lear...   \n",
       "39                    AUTO-ENCODING VARIATIONAL BAYES   \n",
       "40  Beitrag zur Naherungsweisen Integration Totale...   \n",
       "41  ¨Uber die numerische Aufl¨osung von Dif-ferent...   \n",
       "42  2023. Riemannian flow matching on general geom...   \n",
       "\n",
       "                                  citedPaper.abstract  \\\n",
       "0   Guidance serves as a key concept in diffusion ...   \n",
       "1   Despite the significant recent progress in dee...   \n",
       "2   Diffusion models have proven to be highly effe...   \n",
       "3   Denoising diffusion probabilistic models (DDPM...   \n",
       "4   The significant advances in applications of te...   \n",
       "5   Denoising Diffusion Models (DDMs) have emerged...   \n",
       "6   Despite the success of diffusion models (DMs),...   \n",
       "7   Typical diffusion models are trained to accept...   \n",
       "8   Recent ODE/SDE-based generative models, such a...   \n",
       "9   Natural data is redundant yet predominant arch...   \n",
       "10  We explore a new class of diffusion models bas...   \n",
       "11  Diffusion models have emerged as a powerful to...   \n",
       "12  Diffusion models achieve outstanding generativ...   \n",
       "13  Diffusion models have demonstrated remarkable ...   \n",
       "14  We introduce a new paradigm for generative mod...   \n",
       "15  We present rectified flow, a surprisingly simp...   \n",
       "16  Diffusion Denoising Probability Models (DDPM) ...   \n",
       "17  Recent large-scale text-driven synthesis model...   \n",
       "18  We present Imagen, a text-to-image diffusion m...   \n",
       "19  Contrastive models like CLIP have been shown t...   \n",
       "20  By decomposing the image formation process int...   \n",
       "21  Recently, GAN inversion methods combined with ...   \n",
       "22  Guided image synthesis enables everyday users ...   \n",
       "23  In this work, we propose TediGAN, a novel fram...   \n",
       "24  Text-to-image generation has traditionally foc...   \n",
       "25  While the Transformer architecture has become ...   \n",
       "26  Although generative adversarial networks (GANs...   \n",
       "27  Despite the recent advance of Generative Adver...   \n",
       "28  Generative Adversarial Networks (GANs) have re...   \n",
       "29  We introduce a new family of deep neural netwo...   \n",
       "30  While it is nearly effortless for humans to qu...   \n",
       "31                                               None   \n",
       "32                                               None   \n",
       "33                                               None   \n",
       "34  Most of the presented results consist of apply...   \n",
       "35  Diffusion models (DMs) synthesize high-quality...   \n",
       "36  Vision transformers (ViT) have shown promise i...   \n",
       "37  We introduce a novel generative model for vide...   \n",
       "38                                                  ,   \n",
       "39  To make decisions based on a model fit by Auto...   \n",
       "40                                               None   \n",
       "41                                               None   \n",
       "42                                               None   \n",
       "\n",
       "    citedPaper.citationCount citedPaper.publicationDate  \n",
       "0                        9.0                 2023-12-14  \n",
       "1                        9.0                 2023-04-25  \n",
       "2                       62.0                 2023-04-13  \n",
       "3                       91.0                 2023-04-12  \n",
       "4                      124.0                 2023-03-30  \n",
       "5                       28.0                 2023-03-20  \n",
       "6                       19.0                 2023-02-24  \n",
       "7                      177.0                 2023-02-14  \n",
       "8                       42.0                 2023-01-27  \n",
       "9                       93.0                 2022-12-22  \n",
       "10                    1196.0                 2022-12-19  \n",
       "11                      31.0                 2022-12-04  \n",
       "12                     201.0                 2022-10-20  \n",
       "13                      26.0                 2022-10-12  \n",
       "14                     600.0                 2022-10-06  \n",
       "15                     487.0                 2022-09-07  \n",
       "16                      49.0                 2022-08-16  \n",
       "17                    1370.0                 2022-08-02  \n",
       "18                    4894.0                 2022-05-23  \n",
       "19                    5757.0                 2022-04-13  \n",
       "20                   11760.0                 2021-12-20  \n",
       "21                     537.0                 2021-10-06  \n",
       "22                    1151.0                 2021-08-02  \n",
       "23                     325.0                 2021-06-01  \n",
       "24                    4191.0                 2021-02-24  \n",
       "25                   32312.0                 2020-10-22  \n",
       "26                     555.0                 2020-05-18  \n",
       "27                    1064.0                 2019-07-25  \n",
       "28                     445.0                 2018-09-27  \n",
       "29                    4452.0                 2018-06-19  \n",
       "30                    9772.0                 2018-01-11  \n",
       "31                   69797.0                 2015-05-18  \n",
       "32                   39938.0                 2014-05-01  \n",
       "33                    3290.0                 1980-03-01  \n",
       "34                     657.0                       None  \n",
       "35                      12.0                       None  \n",
       "36                      74.0                       None  \n",
       "37                       8.0                       None  \n",
       "38                      24.0                       None  \n",
       "39                   13595.0                       None  \n",
       "40                     493.0                       None  \n",
       "41                       NaN                       None  \n",
       "42                       NaN                       None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_data = get_paper_references(df.loc[0].paperId, fields=[\"title\", \"abstract\", \"citationCount\", \"publicationDate\"], year=2022, limit=150)\n",
    "citations_df = pd.json_normalize(citation_data['data'])\n",
    "citations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         citingPaper.paperId  \\\n",
      "0   0c94efd5648b69f369d278afc2b3419139238c50   \n",
      "1   9f3ae8055e227edb413c54417c9c216f1f554f52   \n",
      "2   db4e8d662dbe80f3ddf78e69b1c1053500894d25   \n",
      "3   50a3f0dd12114fb2ca90a5511a6325524c3f6013   \n",
      "4   5eafc35cedbb28b033009947ca73b40007b2b407   \n",
      "5   4772df95a893061e0fedc9a09c56f95d8926fb9d   \n",
      "6   036fd8b92722023742dc7fceb19a2ea1d56828de   \n",
      "7   ca48013d99a608e800ae34388fe9fba9ea6ca280   \n",
      "8   3dd5ad34012164c4ec9c571a12cc6a7561683dea   \n",
      "9   02487e9dfefdcb667be4dc160780321555662a2e   \n",
      "10  3a66e3a6fe1f9e1d95140f0c8fefc4ff964ba89d   \n",
      "11  46c96074a4e33e90bc01b3c869cac9ea3a0b8fe7   \n",
      "12  d33856de0e4f1499d6a48fdbd91e92700127b2fe   \n",
      "13  e11c67919830bb0a29a86b05936d467227accc81   \n",
      "14  c5a528afd98274902b4987b887f19ecd282ca8bd   \n",
      "\n",
      "                                    citingPaper.title  \\\n",
      "0   Emerging strategies for addressing flood-damag...   \n",
      "1   Generative Adversarial Reviews: When LLMs Beco...   \n",
      "2   A Database of Stress-Strain Properties Auto-ge...   \n",
      "3   Evaluating GPT and BERT models for protein–pro...   \n",
      "4   Paper Copilot: A Self-Evolving and Efficient L...   \n",
      "5   Temporal Graph Neural Network-Powered Paper Re...   \n",
      "6   Harvesting Textual and Structured Data from th...   \n",
      "7   The changing landscape of text mining: a revie...   \n",
      "8   A Comprehensive Survey of Scientific Large Lan...   \n",
      "9   TEG-DB: A Comprehensive Dataset and Benchmark ...   \n",
      "10         Neural Methods for Data-to-text Generation   \n",
      "11  Binarized Simplicial Convolutional Neural Netw...   \n",
      "12  Improving Health Question Answering with Relia...   \n",
      "13  openalexR: An R-Tool for Collecting Bibliometr...   \n",
      "14  BioBBC: a multi-feature model that enhances th...   \n",
      "\n",
      "                                 citingPaper.abstract  \\\n",
      "0                                                None   \n",
      "1   The peer review process is fundamental to scie...   \n",
      "2                                                None   \n",
      "3   Abstract Motivation Detecting protein–protein ...   \n",
      "4   As scientific research proliferates, researche...   \n",
      "5   Due to the rapid growth of scientific publicat...   \n",
      "6   HAL (Hyper Articles en Ligne) is the French na...   \n",
      "7   In ecology and evolutionary biology, the synth...   \n",
      "8   In many scientific fields, large language mode...   \n",
      "9   Text-Attributed Graphs (TAGs) augment graph st...   \n",
      "10  The neural boom that has sparked natural langu...   \n",
      "11  Graph Neural Networks have the limitation of p...   \n",
      "12  In today's digital world, seeking answers to h...   \n",
      "13  Bibliographic databases are indispensable sour...   \n",
      "14                                               None   \n",
      "\n",
      "    citingPaper.citationCount citingPaper.publicationDate  \n",
      "0                           0                  2025-01-01  \n",
      "1                           0                  2024-12-09  \n",
      "2                           0                  2024-11-23  \n",
      "3                           2                  2024-09-11  \n",
      "4                           0                  2024-09-06  \n",
      "5                           0                  2024-08-27  \n",
      "6                           0                  2024-07-30  \n",
      "7                           0                  2024-07-01  \n",
      "8                           6                  2024-06-16  \n",
      "9                           2                  2024-06-14  \n",
      "10                          4                  2024-05-08  \n",
      "11                          1                  2024-05-07  \n",
      "12                          2                  2024-04-12  \n",
      "13                          5                  2024-04-11  \n",
      "14                          0                  2024-04-02  \n"
     ]
    }
   ],
   "source": [
    "paper_id = \"649def34f8be52c8b66281af98ae884c09aef38b\"\n",
    "citation_data = get_paper_citations(paper_id, fields=[\"title\", \"abstract\", \"citationCount\", \"publicationDate\"], year=2022, limit=15)\n",
    "\n",
    "# Convert citation data to a pandas DataFrame\n",
    "if citation_data and 'data' in citation_data:\n",
    "    citations_df = pd.json_normalize(citation_data['data'])\n",
    "    print(citations_df)\n",
    "else:\n",
    "    print(\"No citation data available.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
