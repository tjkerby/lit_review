{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tjker\\Desktop\\Research\\Projects\\lit_review\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from langchain_neo4j import Neo4jGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/.env', override=True)\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'numberOfNodes': 878}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD)\n",
    "\n",
    "cypher = \"\"\"\n",
    "MATCH (n)\n",
    "RETURN count(n) AS numberOfNodes\n",
    "\"\"\"\n",
    "\n",
    "result = kg.query(cypher)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.query(\"\"\"\n",
    "    DROP INDEX abstract_embeddings    \n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping text for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# model_id = \"bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\"\n",
    "# model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "def compute_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():     \n",
    "        outputs = model(**inputs) \n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze(0).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kg.query(\"\"\"\n",
    "    MATCH (p:Paper) \n",
    "    RETURN elementId(p) AS node_id, p.abstract AS abstract\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 771/771 [16:14<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for record in tqdm(result):\n",
    "    node_id = record[\"node_id\"]\n",
    "    abstract = record[\"abstract\"]\n",
    "    \n",
    "    if abstract:\n",
    "        # embedding = model.encode(abstract)\n",
    "        embedding = compute_embedding(abstract)\n",
    "        kg.query(\"\"\"\n",
    "            MATCH (p:Paper) WHERE elementId(p) = $node_id\n",
    "            SET p.abstractEmbedding = $embedding\n",
    "            RETURN elementId(p) AS node_id, p.abstract AS abstract\n",
    "            \"\"\", params={\"node_id\":node_id, \"embedding\":embedding}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.query(\"\"\"\n",
    "  CREATE VECTOR INDEX abstract_embeddings IF NOT EXISTS\n",
    "  FOR (p:Paper) ON (p.abstractEmbedding) \n",
    "  OPTIONS { indexConfig: {\n",
    "    `vector.dimensions`: 2048,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "  }}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 2,\n",
       "  'name': 'abstract_embeddings',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'VECTOR',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Paper'],\n",
       "  'properties': ['abstractEmbedding'],\n",
       "  'indexProvider': 'vector-2.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': neo4j.time.DateTime(2025, 1, 20, 20, 18, 58, 444000000, tzinfo=<UTC>),\n",
       "  'readCount': 61}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.query(\"\"\"\n",
    "  SHOW VECTOR INDEXES\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paper.title': 'LightFace: A Hybrid Deep Face Recognition Framework',\n",
       "  'paper.abstract': 'Face recognition constitutes a relatively a popular area which has emerged from the rulers of the social media to top universities in the world. Those frontiers and rule makers recently designed deep learning based custom face recognition models. A modern face recognition pipeline consists of four common stages: detecting, alignment, representation and verification. However, face recognition studies mainly mention the representation stage of a pipeline. In this paper, first of all a review face recognition has been done and then the description of the developed lightweight hybrid high performance face recognition framework has been made. Its hybrid feature enables to switch face recognition models among state-of-the-art ones.',\n",
       "  'score': 0.8669426441192627},\n",
       " {'paper.title': 'GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium',\n",
       "  'paper.abstract': 'When it comes to the formation of real-looking images using some complex models, Generative Adversarial Networks do not disappoint. The complex models involved are often the types with infeasible maximum likelihoods. Be that as it may, there is not yet any proof for the convergence of GANs training. This paper proposes a TTUR (a two-time scale update rule) for training the Generative Adversarial Networks with a descent of stochastic gradient based on haphazard loss functions. The two time-scale update rule has separate learning rates for the generator and the discriminator. With the aid of the stochastic approximation theory, this paper demonstrates that the TTUR reaches a point of convergence under the influence of mild assumption to a kind of remote and stationary state known as Nash equilibrium. This unification or meeting point principle also applies to the widespread Adam optimization. This is a form or replacement optimization algorithm designed into stochastic gradient descent and used for tutoring the deep learning models in the system. For the Adam optimization theory, this paper evinces that it is in line with the dynamics of a weighty ball in a frictional state. Thus, we prove that it favours flat minina in the objective perspective of things. To carry out an evaluation of how GANs perform during the image creation process, this paper presents what we have termed the \\'Fréchet Inception Distance\", also known as FID—a concept known to dwell on the resemblance between the images created and the real ones in a way that is more improved compared to the Inception Score. Experimentally, the TTUR helps in the bettering of DCGANs and Improved Wasserstein GANs (WGAN-GP). This makes it perform better than the traditional CelebA GAN training, LSUN Bedrooms, CIFAR-10, SVHN and the One Billion Word Benchmark.',\n",
       "  'score': 0.8631999492645264},\n",
       " {'paper.title': 'Image Analogies',\n",
       "  'paper.abstract': 'This paper describes a new framework for processing images by example, called \"image analogies.\"based on scanned real-world examples; and texture-by-numbers, in which realistic scenes, composed of a variety of textures, are created using a simple painting interface.',\n",
       "  'score': 0.8622632026672363},\n",
       " {'paper.title': 'Nonequilibrium thermodynamics',\n",
       "  'paper.abstract': 'Aspects of the modern dynamical systems approach to thermodynamics of stationary states out of equilibrium with attention to the original conceptions which arose at the beginnings of Statistical Mechanics',\n",
       "  'score': 0.8609955310821533},\n",
       " {'paper.title': 'Making Images Real Again: A Comprehensive Survey on Deep Image Composition',\n",
       "  'paper.abstract': \"As a common image editing operation, image composition aims to combine the foreground from one image and another background image, resulting in a composite image. However, there are many issues that could make the composite images unrealistic. These issues can be summarized as the inconsistency between foreground and background, which includes appearance inconsistency (e.g., incompatible illumination), geometry inconsistency (e.g., unreasonable size), and semantic inconsistency (e.g., mismatched semantic context). Image composition task could be decomposed into multiple sub-tasks, in which each sub-task targets at one or more issues. Specifically, object placement aims to find reasonable scale, location, and shape for the foreground. Image blending aims to address the unnatural boundary between foreground and background. Image harmonization aims to adjust the illumination statistics of foreground. Shadow generation aims to generate plausible shadow for the foreground. These sub-tasks can be executed sequentially or parallelly to acquire realistic composite images. To the best of our knowledge, there is no previous survey on image composition. In this paper, we conduct comprehensive survey over the sub-tasks and combinatorial task of image composition. For each one, we summarize the existing methods, available datasets, and common evaluation metrics. Datasets and codes for image composition are summarized at https://github.com/bcmi/Awesome-Image-Composition. We have also contributed the first image composition toolbox: libcom https://github.com/bcmi/libcom, which assembles 10+ image composition related functions (e.g., image blending, image harmonization, object placement, shadow generation, generative composition). The ultimate goal of this toolbox is solving all the problems related to image composition with simple `import libcom'.\",\n",
       "  'score': 0.8603029251098633}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Transformer architecture\"\n",
    "# question_embedding = model.encode(question)\n",
    "question_embedding = compute_embedding(question)\n",
    "\n",
    "kg.query(\"\"\"\n",
    "    CALL db.index.vector.queryNodes(\n",
    "        'abstract_embeddings', \n",
    "        $top_k, \n",
    "        $question_embedding\n",
    "        ) YIELD node AS paper, score\n",
    "    RETURN paper.title, paper.abstract, score\n",
    "    \"\"\", \n",
    "    params={\"top_k\":5,\n",
    "            \"question_embedding\": question_embedding\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Fulltext index for title searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg.query(\"\"\"\n",
    "#     CREATE FULLTEXT INDEX paperTitleIndex FOR (p:Paper) ON EACH [p.title]\n",
    "#     \"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'node.paperId': 'ca743e75ce090bbf686307e41bd8747661768fbe',\n",
       "  'score': 12.453763008117676}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "title = 'Latent Space Editing in Transformer-Based Flow Matching'\n",
    "kg.query(\"\"\"\n",
    "    CALL db.index.fulltext.queryNodes('paperTitleIndex', $title)     \n",
    "    YIELD node, score\n",
    "    RETURN node.paperId, score\n",
    "    LIMIT 1\n",
    "    \"\"\", params={'title': title}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading PDFs and adding to KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "pdf_urls = [\n",
    "    'https://arxiv.org/pdf/2312.10825', \n",
    "    'https://arxiv.org/pdf/2211.13227',\n",
    "    'https://arxiv.org/pdf/2312.04410',\n",
    "    \"https://arxiv.org/pdf/2210.05559\",\n",
    "    'https://arxiv.org/pdf/2312.07330',\n",
    "    'https://www.mdpi.com/1999-4893/17/3/125',\n",
    "    \"https://arxiv.org/pdf/2412.05984\",\n",
    "    \"https://arxiv.org/pdf/2210.06462\",\n",
    "    \"https://pdf.sciencedirectassets.com/315710/1-s2.0-S2468502X24X00029/1-s2.0-S2468502X24000019/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQD9bqDAJg03RCd8F1xN1Do2wEO9pfqK%2FYutivd1i2roFAIhAKpkWXP%2BIKEx9E6JSYUP1BJdXNYDcWwdKIXU%2FEmNQ7GvKrwFCKv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1IgxgoiaPGOeSGzPKN9IqkAWkti50dRew%2FQd9dU4dDpv1RpeyBy0JLYTuBpQZnlIULcjDzXIqOFGNJgcjxgJXUF8CeMERSUz4q1MSZPRz8jRIMsBLqEPxGFNO0Jpf2BD0wCdumLfMvFgLmXh0q55WBHClYJ2HmJCqiLHaXsqvPDpGlQUS6o272lk6I9LEPyiRxEouswlwgBTDthqHR8yXeCX3v4G%2Bx3wgwz%2B4qHPtit3Og96AkBxvNmlZWd8PZiYl153fFFbabv09zPPplA%2Fo6F8NQasq18dTYfN710JLmI7lZ4203g2xJJ77vZNBlcJdjG%2BTY83uRMBBrzom%2FtSxv2PJJa05dHJjIp6v55ygwNIF0lMP4GO%2B1ZJ2N%2FN2Zumjvc%2FM7MY4TE7zRAsyjf2ZmvLDmVgJCjD8PaECHQJm5%2Fg9IvSVcKQsPId%2FyTTwiAxDOVo4JjeGj6w6XVwajHfvXl%2BvU4ou7Rqmp7%2F4hcCvnNy9pRvnpAmmRn4aeOIkdL0ykmhGuopfyILMyGZu5Nk%2F0Ko7dyKlUEr1fYR10KPelX60KZ9tkqphocAVn8mLKDA9Bn%2BEWjkt3RDyOVSKePxd%2FjDSz6o5yprz%2BVR0UyQH0d93JBFSnIrAZ8YN40nSKdT%2FVRZyQWoFChCRVtqMtVhxMkBmCZP0HQ0JdjRewknHpMyGY6PpSYrFlp0vBNaEVZnQqw8GVTHe7MBPAAuXxm1vsNfwTZ6TVWPGoqxpHo1%2FPk3BIkfU7e1biUXR6tmSPbYVu0THxC0sEmB9f78LmaDzPIOyH%2FpdhKrq4bZRWPJVa5of9%2Bx%2BIoWiZ%2BOykeT8gOopw6ktR6Fd%2F2gsxj01QCeFlDJvFpZ%2Biot9t59TeqAAK%2FKGKSOKGivcVstWLzG5QxMr7jDOm7q8BjqwAUA4cy1qm1K%2B7jEqASWFknxzorw2upxSFuj8kIF4Z6KWK2V46N%2B9hwSp1GC18Q8IbccYC7A0cHty%2FzVuhNmWcEA5LC0CGqRXMfryONG0FZL4MtDM3yoJsHBUE%2BcaeXQnzWD%2BZUOJUS%2BVHtncLI6UBl8GXKkr3FIzBqawQ35IYFag4jgwcFHgYN80o33LVNPPv27WLoFnLHb5%2FsnqJLews%2BkY79%2B4Pm34d2f2W0JY3Rv6&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250120T184637Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY4YQRFCS3%2F20250120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=ea99f34a396f71a81945c07ec0473983c547caa2f90fdf5b6198d945eefdf107&hash=222b44b292bc8ad7b943efb168b684155393f92d7c0b2ce7a95ac142a06f56f4&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S2468502X24000019&tid=spdf-0969c9cf-fab2-4073-8cb7-4c1c20fb5c2a&sid=d65f2cef3561484338481245b5940b16f742gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=13135f5453535c045457&rr=90513a748b9c2c69&cc=us\",\n",
    "    \"https://arxiv.org/pdf/2302.05543\",\n",
    "    \"https://arxiv.org/pdf/2210.10960\",\n",
    "    \"https://arxiv.org/pdf/2307.12868\",\n",
    "    \"https://arxiv.org/pdf/2210.05559\",\n",
    "    \"https://arxiv.org/pdf/2208.01626\",\n",
    "    \"https://arxiv.org/pdf/2112.05744\",\n",
    "    \"https://arxiv.org/pdf/2401.18085\",\n",
    "    \"https://arxiv.org/pdf/2104.00820\",\n",
    "    \"https://arxiv.org/pdf/2402.17723\",\n",
    "    \"https://arxiv.org/pdf/2303.11073\",\n",
    "    \"https://arxiv.org/pdf/2212.08698\",\n",
    "    \"https://arxiv.org/pdf/2205.12952\",\n",
    "    \"https://arxiv.org/pdf/2004.05571\",\n",
    "    \"https://arxiv.org/pdf/2204.11824v1\",\n",
    "    \"https://arxiv.org/pdf/2111.15640\",\n",
    "    \"https://arxiv.org/pdf/2211.12572\",\n",
    "    \"https://arxiv.org/pdf/2106.05744\"\n",
    "]\n",
    "\n",
    "for i, pdf_url in enumerate(pdf_urls):\n",
    "    response = requests.get(pdf_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(f\"documents/paper_{i}.pdf\", 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"PDF saved as paper_{i}.pdf\")\n",
    "    else:\n",
    "        print(f\"Failed to download PDF. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_0.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/18=[====                                    ] ( 2/18=[======                                  ] ( 3/18=[========                                ] ( 4/18==[===========                             ] ( 5/1=[=============                           ] ( 6/1=[===============                         ] ( 7/1=[=================                       ] ( 8/1==[====================                    ] ( 9/18=[======================                  ] (10/18=[========================                ] (11/18=[==========================              ] (12/18=[============================            ] (13/18==[===============================         ] (14/1=[=================================       ] (15/1=[===================================     ] (16/1=[=====================================   ] (17/1==[========================================] (18/18]\n",
      "[0.9997963905334473, 0.9809634685516357, 0.9802992343902588]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_1.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/15==[=====                                   ] ( 2/1=[========                                ] ( 3/15==[==========                              ] ( 4/15==[=============                           ] ( 5/1=[================                        ] ( 6/15==[==================                      ] ( 7/15==[=====================                   ] ( 8/1=[========================                ] ( 9/15==[==========================              ] (10/15==[=============================           ] (11/1=[================================        ] (12/15==[==================================      ] (13/15==[=====================================   ] (14/1=[========================================] (15/15]\n",
      "[0.9934802055358887, 0.9789113998413086, 0.9761033058166504]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_2.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/15==[=====                                   ] ( 2/1=[========                                ] ( 3/15==[==========                              ] ( 4/15==[=============                           ] ( 5/1=[================                        ] ( 6/15==[==================                      ] ( 7/15==[=====================                   ] ( 8/1=[========================                ] ( 9/15==[==========================              ] (10/15==[=============================           ] (11/1=[================================        ] (12/15==[==================================      ] (13/15==[=====================================   ] (14/1=[========================================] (15/15]\n",
      "[0.9837110042572021, 0.9725377559661865, 0.9714546203613281]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_3.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2=[=======                                 ] ( 4/2=[=========                               ] ( 5/2=[===========                             ] ( 6/2=[=============                           ] ( 7/2=[===============                         ] ( 8/2=[=================                       ] ( 9/2=[===================                     ] (10/2[====================                    ] (11/21=[======================                  ] (12/21=[========================                ] (13/21=[==========================              ] (14/21=[============================            ] (15/21=[==============================          ] (16/21=[================================        ] (17/21=[==================================      ] (18/21=[====================================    ] (19/21=[======================================  ] (20/21[========================================] (21/21]\n",
      "[0.9985926151275635, 0.9832584857940674, 0.982003927230835]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_4.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/19=[====                                    ] ( 2/19=[======                                  ] ( 3/19=[========                                ] ( 4/19=[==========                              ] ( 5/19=[============                            ] ( 6/19=[==============                          ] ( 7/19=[================                        ] ( 8/19=[==================                      ] ( 9/19==[=====================                   ] (10/1=[=======================                 ] (11/1=[=========================               ] (12/1=[===========================             ] (13/1=[=============================           ] (14/1=[===============================         ] (15/1=[=================================       ] (16/1=[===================================     ] (17/1=[=====================================   ] (18/1=[========================================] (19/19]\n",
      "[0.9932358264923096, 0.9775490760803223, 0.9749095439910889]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_6.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/15==[=====                                   ] ( 2/1=[========                                ] ( 3/15==[==========                              ] ( 4/15==[=============                           ] ( 5/1=[================                        ] ( 6/15==[==================                      ] ( 7/15==[=====================                   ] ( 8/1=[========================                ] ( 9/15==[==========================              ] (10/15==[=============================           ] (11/1=[================================        ] (12/15==[==================================      ] (13/15==[=====================================   ] (14/1=[========================================] (15/15]\n",
      "[0.9983997344970703, 0.9783437252044678, 0.9763391017913818]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_7.pdf...\n",
      "[                                        ] (0/3[=                                       ] ( 1/3[==                                      ] ( 2/31[===                                     ] ( 3/3=[=====                                   ] ( 4/3[======                                  ] ( 5/31[=======                                 ] ( 6/3=[=========                               ] ( 7/3[==========                              ] ( 8/31[===========                             ] ( 9/3[============                            ] (10/31=[==============                          ] (11/31[===============                         ] (12/3[================                        ] (13/31=[==================                      ] (14/31[===================                     ] (15/3[====================                    ] (16/31[=====================                   ] (17/3=[=======================                 ] (18/3[========================                ] (19/31[=========================               ] (20/3=[===========================             ] (21/3[============================            ] (22/31[=============================           ] (23/3[==============================          ] (24/31=[================================        ] (25/31[=================================       ] (26/3[==================================      ] (27/31=[====================================    ] (28/31[=====================================   ] (29/3[======================================  ] (30/31[========================================] (31/31]\n",
      "[0.9891996383666992, 0.9750938415527344, 0.9745197296142578]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_9.pdf...\n",
      "[                                        ] (0/1==[===                                     ] ( 1/1==[======                                  ] ( 2/12===[==========                              ] ( 3/12==[=============                           ] ( 4/1==[================                        ] ( 5/12===[====================                    ] ( 6/12==[=======================                 ] ( 7/1==[==========================              ] ( 8/12===[==============================          ] ( 9/12==[=================================       ] (10/1==[====================================    ] (11/12===[========================================] (12/12]\n",
      "[0.9955148696899414, 0.9801628589630127, 0.9756491184234619]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_10.pdf...\n",
      "[                                        ] (0/3[=                                       ] ( 1/3[==                                      ] ( 2/35[===                                     ] ( 3/3[====                                    ] ( 4/35[=====                                   ] ( 5/3[======                                  ] ( 6/35[========                                ] ( 7/35=[=========                               ] ( 8/3[==========                              ] ( 9/35[===========                             ] (10/3[============                            ] (11/35[=============                           ] (12/3[==============                          ] (13/35[================                        ] (14/35=[=================                       ] (15/3[==================                      ] (16/35[===================                     ] (17/3[====================                    ] (18/35[=====================                   ] (19/3[======================                  ] (20/35[========================                ] (21/35=[=========================               ] (22/3[==========================              ] (23/35[===========================             ] (24/3[============================            ] (25/35[=============================           ] (26/3[==============================          ] (27/35[================================        ] (28/35=[=================================       ] (29/3[==================================      ] (30/35[===================================     ] (31/3[====================================    ] (32/35[=====================================   ] (33/3[======================================  ] (34/35[========================================] (35/35]\n",
      "[0.9760105609893799, 0.9739210605621338, 0.9723124504089355]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_11.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2[====                                    ] ( 3/26=[======                                  ] ( 4/26[=======                                 ] ( 5/2=[=========                               ] ( 6/2[==========                              ] ( 7/26=[============                            ] ( 8/26[=============                           ] ( 9/2=[===============                         ] (10/2[================                        ] (11/26=[==================                      ] (12/26=[====================                    ] (13/26[=====================                   ] (14/2=[=======================                 ] (15/2[========================                ] (16/26=[==========================              ] (17/26[===========================             ] (18/2=[=============================           ] (19/2[==============================          ] (20/26=[================================        ] (21/26[=================================       ] (22/2=[===================================     ] (23/2[====================================    ] (24/26=[======================================  ] (25/26=[========================================] (26/26]\n",
      "[0.9903628826141357, 0.9793212413787842, 0.9685969352722168]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_12.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2=[=======                                 ] ( 4/2=[=========                               ] ( 5/2=[===========                             ] ( 6/2=[=============                           ] ( 7/2=[===============                         ] ( 8/2=[=================                       ] ( 9/2=[===================                     ] (10/2[====================                    ] (11/21=[======================                  ] (12/21=[========================                ] (13/21=[==========================              ] (14/21=[============================            ] (15/21=[==============================          ] (16/21=[================================        ] (17/21=[==================================      ] (18/21=[====================================    ] (19/21=[======================================  ] (20/21[========================================] (21/21]\n",
      "[0.9985926151275635, 0.9832584857940674, 0.982003927230835]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_13.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/19=[====                                    ] ( 2/19=[======                                  ] ( 3/19=[========                                ] ( 4/19=[==========                              ] ( 5/19=[============                            ] ( 6/19=[==============                          ] ( 7/19=[================                        ] ( 8/19=[==================                      ] ( 9/19==[=====================                   ] (10/1=[=======================                 ] (11/1=[=========================               ] (12/1=[===========================             ] (13/1=[=============================           ] (14/1=[===============================         ] (15/1=[=================================       ] (16/1=[===================================     ] (17/1=[=====================================   ] (18/1=[========================================] (19/19]\n",
      "[0.9997541904449463, 0.9824821949005127, 0.9815785884857178]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_14.pdf...\n",
      "[                                        ] (0/1==[===                                     ] ( 1/1===[=======                                 ] ( 2/1==[==========                              ] ( 3/11===[==============                          ] ( 4/11===[==================                      ] ( 5/11==[=====================                   ] ( 6/1===[=========================               ] ( 7/1===[=============================           ] ( 8/1==[================================        ] ( 9/11===[====================================    ] (10/11==[========================================] (11/11]\n",
      "[0.8815102577209473, 0.8787178993225098, 0.8770341873168945]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_15.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2=[=======                                 ] ( 4/2=[=========                               ] ( 5/2[==========                              ] ( 6/22=[============                            ] ( 7/22=[==============                          ] ( 8/22=[================                        ] ( 9/22=[==================                      ] (10/22[====================                    ] (11/22=[=====================                   ] (12/2=[=======================                 ] (13/2=[=========================               ] (14/2=[===========================             ] (15/2=[=============================           ] (16/2[==============================          ] (17/22=[================================        ] (18/22=[==================================      ] (19/22=[====================================    ] (20/22=[======================================  ] (21/22[========================================] (22/22]\n",
      "[0.9998459815979004, 0.9811844825744629, 0.9771273136138916]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_16.pdf...\n",
      "[                                        ] (0/1===[====                                    ] ( 1/10===[========                                ] ( 2/10===[============                            ] ( 3/10===[================                        ] ( 4/10===[====================                    ] ( 5/10===[========================                ] ( 6/10===[============================            ] ( 7/10===[================================        ] ( 8/10===[====================================    ] ( 9/10===[========================================] (10/10]\n",
      "[0.9902858734130859, 0.9812815189361572, 0.9800574779510498]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_17.pdf...\n",
      "[                                        ] (0/1==[===                                     ] ( 1/1===[=======                                 ] ( 2/1==[==========                              ] ( 3/11===[==============                          ] ( 4/11===[==================                      ] ( 5/11==[=====================                   ] ( 6/1===[=========================               ] ( 7/1===[=============================           ] ( 8/1==[================================        ] ( 9/11===[====================================    ] (10/11==[========================================] (11/11]\n",
      "[0.9926371574401855, 0.9787411689758301, 0.9785721302032471]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_18.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2=[=======                                 ] ( 4/2=[=========                               ] ( 5/2[==========                              ] ( 6/22=[============                            ] ( 7/22=[==============                          ] ( 8/22=[================                        ] ( 9/22=[==================                      ] (10/22[====================                    ] (11/22=[=====================                   ] (12/2=[=======================                 ] (13/2=[=========================               ] (14/2=[===========================             ] (15/2=[=============================           ] (16/2[==============================          ] (17/22=[================================        ] (18/22=[==================================      ] (19/22=[====================================    ] (20/22=[======================================  ] (21/22[========================================] (22/22]\n",
      "[0.8815102577209473, 0.8787178993225098, 0.8770341873168945]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_19.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2[======                                  ] ( 4/23=[========                                ] ( 5/23=[==========                              ] ( 6/23=[============                            ] ( 7/23[=============                           ] ( 8/2=[===============                         ] ( 9/2=[=================                       ] (10/2=[===================                     ] (11/2[====================                    ] (12/23=[======================                  ] (13/23=[========================                ] (14/23=[==========================              ] (15/23[===========================             ] (16/2=[=============================           ] (17/2=[===============================         ] (18/2=[=================================       ] (19/2[==================================      ] (20/23=[====================================    ] (21/23=[======================================  ] (22/23[========================================] (23/23]\n",
      "[0.9916782379150391, 0.9789519309997559, 0.9786486625671387]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_20.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2[==                                      ] ( 2/29=[====                                    ] ( 3/29[=====                                   ] ( 4/2[======                                  ] ( 5/29=[========                                ] ( 6/29[=========                               ] ( 7/2=[===========                             ] ( 8/2[============                            ] ( 9/29[=============                           ] (10/2=[===============                         ] (11/2[================                        ] (12/29[=================                       ] (13/2=[===================                     ] (14/2[====================                    ] (15/29=[======================                  ] (16/29[=======================                 ] (17/2[========================                ] (18/29=[==========================              ] (19/29[===========================             ] (20/2[============================            ] (21/29=[==============================          ] (22/29[===============================         ] (23/2=[=================================       ] (24/2[==================================      ] (25/29[===================================     ] (26/2=[=====================================   ] (27/2[======================================  ] (28/29=[========================================] (29/29]\n",
      "[0.9971671104431152, 0.982921838760376, 0.9822351932525635]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_21.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2[======                                  ] ( 4/23=[========                                ] ( 5/23=[==========                              ] ( 6/23=[============                            ] ( 7/23[=============                           ] ( 8/2=[===============                         ] ( 9/2=[=================                       ] (10/2=[===================                     ] (11/2[====================                    ] (12/23=[======================                  ] (13/23=[========================                ] (14/23=[==========================              ] (15/23[===========================             ] (16/2=[=============================           ] (17/2=[===============================         ] (18/2=[=================================       ] (19/2[==================================      ] (20/23=[====================================    ] (21/23=[======================================  ] (22/23[========================================] (23/23]\n",
      "[0.9988276958465576, 0.9830124378204346, 0.9819929599761963]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_22.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/17=[====                                    ] ( 2/17==[=======                                 ] ( 3/1=[=========                               ] ( 4/1=[===========                             ] ( 5/1==[==============                          ] ( 6/17=[================                        ] ( 7/17=[==================                      ] ( 8/17==[=====================                   ] ( 9/1=[=======================                 ] (10/1=[=========================               ] (11/1==[============================            ] (12/17=[==============================          ] (13/17=[================================        ] (14/17==[===================================     ] (15/1=[=====================================   ] (16/1==[========================================] (17/17]\n",
      "[0.9998478889465332, 0.9854319095611572, 0.9847691059112549]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_23.pdf...\n",
      "[                                        ] (0/2[=                                       ] ( 1/2=[===                                     ] ( 2/2=[=====                                   ] ( 3/2=[=======                                 ] ( 4/2=[=========                               ] ( 5/2[==========                              ] ( 6/22=[============                            ] ( 7/22=[==============                          ] ( 8/22=[================                        ] ( 9/22=[==================                      ] (10/22[====================                    ] (11/22=[=====================                   ] (12/2=[=======================                 ] (13/2=[=========================               ] (14/2=[===========================             ] (15/2=[=============================           ] (16/2[==============================          ] (17/22=[================================        ] (18/22=[==================================      ] (19/22=[====================================    ] (20/22=[======================================  ] (21/22[========================================] (22/22]\n",
      "[0.9975340366363525, 0.9825019836425781, 0.9823520183563232]\n",
      "Processing C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_24.pdf...\n",
      "[                                        ] (0/1=[==                                      ] ( 1/15==[=====                                   ] ( 2/1=[========                                ] ( 3/15==[==========                              ] ( 4/15==[=============                           ] ( 5/1=[================                        ] ( 6/15==[==================                      ] ( 7/15==[=====================                   ] ( 8/1=[========================                ] ( 9/15==[==========================              ] (10/15==[=============================           ] (11/1=[================================        ] (12/15==[==================================      ] (13/15==[=====================================   ] (14/1=[========================================] (15/15]\n",
      "[0.99825119972229, 0.9841289520263672, 0.9823834896087646]\n"
     ]
    }
   ],
   "source": [
    "import pymupdf4llm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 3000,\n",
    "    chunk_overlap  = 300,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "for i in range(25):\n",
    "    if i in [5, 8]:\n",
    "        continue\n",
    "    md_text = pymupdf4llm.to_markdown(f\"C:/Users/tjker/Desktop/Research/Projects/lit_review/lit_review/documents/paper_{i}.pdf\")\n",
    "\n",
    "    split_text = text_splitter.split_text(md_text)\n",
    "\n",
    "    # abstract_pattern = r\"(?i)(?:^|\\n)\\s*(?:\\*\\*|##?)\\s*abstract\\s*(?:\\*\\*|##?)?\\s*\\n+([\\s\\S]*?)(?=\\n\\s*(?:\\*\\*|##?|###?)\\s*\\w+|\\Z)\"\n",
    "    abstract_pattern = r\"(?i)(?:^|\\n)\\s*(?:\\*\\*|#+)\\s*abstract\\s*(?:\\*\\*|#+)?\\s*\\n+([\\s\\S]*?)(?=\\n\\s*(?:\\*\\*|#+)\\s*\\w+|\\Z)\"\n",
    "\n",
    "    match = re.search(abstract_pattern, split_text[0])\n",
    "    abstract = match.group(1) if match else \"Abstract not found\"\n",
    "    abstract = re.sub(r\"[\\n_]+\", \" \", abstract).strip()\n",
    "    abstract = abstract.replace(\"- \", \"\")\n",
    "    paper_embedding = compute_embedding(abstract)\n",
    "\n",
    "    results = kg.query(\"\"\"\n",
    "        CALL db.index.vector.queryNodes(\n",
    "            'abstract_embeddings', \n",
    "            $top_k, \n",
    "            $paper_embedding\n",
    "            ) YIELD node AS paper, score\n",
    "        RETURN paper.title, paper.abstract, score\n",
    "        \"\"\", \n",
    "        params={\"top_k\":3,\n",
    "                \"paper_embedding\": paper_embedding\n",
    "                })\n",
    "\n",
    "    scores = [x['score'] for x in results]\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "VECTOR_INDEX_NAME = 'paper_chunks'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a KG from text documents\n",
    "This is the next thing to do on my list\n",
    "See https://learn.deeplearning.ai/courses/knowledge-graphs-rag for help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Common data processing\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from environment\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "# Note the code below is unique to this course environment, and not a \n",
    "# standard part of Neo4j's integration with OpenAI. Remove if running \n",
    "# in your own environment.\n",
    "OPENAI_ENDPOINT = os.getenv('OPENAI_BASE_URL') + '/embeddings'\n",
    "\n",
    "# Global constants\n",
    "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "def create_paper_chunks(file):\n",
    "    chunks_with_metadata = []\n",
    "    md_text = pymupdf4llm.to_markdown(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_form10k_data_from_file(file):\n",
    "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
    "    file_as_object = json.load(open(file)) # open the json file\n",
    "    for item in ['item1','item1a','item7','item7a']: # pull these keys from the json\n",
    "        print(f'Processing {item} from {file}') \n",
    "        item_text = file_as_object[item] # grab the text of the item\n",
    "        item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
    "        chunk_seq_id = 0\n",
    "        for chunk in item_text_chunks[:20]: # only take the first 20 chunks\n",
    "            form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
    "            # finally, construct a record with metadata and the chunk text\n",
    "            chunks_with_metadata.append({\n",
    "                'text': chunk, \n",
    "                'f10kItem': item,\n",
    "                'chunkSeqId': chunk_seq_id,\n",
    "                'formId': f'{form_id}', # pulled from the filename\n",
    "                'chunkId': f'{form_id}-{item}-chunk{chunk_seq_id:04d}',\n",
    "                'names': file_as_object['names'],\n",
    "                'cik': file_as_object['cik'],\n",
    "                'cusip6': file_as_object['cusip6'],\n",
    "                'source': file_as_object['source'],\n",
    "            })\n",
    "            chunk_seq_id += 1\n",
    "        print(f'\\tSplit into {chunk_seq_id} chunks')\n",
    "    return chunks_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.names = $chunkParam.names,\n",
    "        mergedChunk.formId = $chunkParam.formId, \n",
    "        mergedChunk.cik = $chunkParam.cik, \n",
    "        mergedChunk.cusip6 = $chunkParam.cusip6, \n",
    "        mergedChunk.source = $chunkParam.source, \n",
    "        mergedChunk.f10kItem = $chunkParam.f10kItem, \n",
    "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId, \n",
    "        mergedChunk.text = $chunkParam.text\n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = 0\n",
    "for chunk in first_file_chunks:\n",
    "    print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkId']}\")\n",
    "    kg.query(merge_chunk_node_query, \n",
    "            params={\n",
    "                'chunkParam': chunk\n",
    "            })\n",
    "    node_count += 1\n",
    "print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
    "          FOR (c:Chunk) ON (c.textEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "    MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "    WITH chunk, genai.vector.encode(\n",
    "      chunk.text, \n",
    "      \"OpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey, \n",
    "        endpoint: $openAiEndpoint\n",
    "      }) AS vector\n",
    "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "    \"\"\", \n",
    "    params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neo4j_vector_search(question):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  vector_search_query = \"\"\"\n",
    "    WITH genai.vector.encode(\n",
    "      $question, \n",
    "      \"OpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey,\n",
    "        endpoint: $openAiEndpoint\n",
    "      }) AS question_embedding\n",
    "    CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
    "    RETURN score, node.text AS text\n",
    "  \"\"\"\n",
    "  similar = kg.query(vector_search_query, \n",
    "                     params={\n",
    "                      'question': question, \n",
    "                      'openAiApiKey':OPENAI_API_KEY,\n",
    "                      'openAiEndpoint': OPENAI_ENDPOINT,\n",
    "                      'index_name':VECTOR_INDEX_NAME, \n",
    "                      'top_k': 10})\n",
    "  return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = neo4j_vector_search(\n",
    "    'In a single sentence, tell me about Netapp.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    node_label=VECTOR_NODE_LABEL,\n",
    "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
    "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
    ")\n",
    "\n",
    "retriever = neo4j_vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettychain(question: str) -> str:\n",
    "    \"\"\"Pretty print the chain's response to a question\"\"\"\n",
    "    response = chain({\"question\": question},\n",
    "        return_only_outputs=True,)\n",
    "    print(textwrap.fill(response['answer'], 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Apple. \n",
    "    Limit your answer to a single sentence.\n",
    "    If you are unsure about the answer, say you don't know.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
